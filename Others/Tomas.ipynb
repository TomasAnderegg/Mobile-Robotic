{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we tried to divide the tasks as follows: Victor handled the Vision part, Hoang worked on Path Planning and Motion Control, while Tomas focused on filtering, kidnapping, and local avoidance. As we progressed with the project, we quickly realized there were different ways to implement things. Unfortunately, due to the robot's imprecise sensors, we encountered many difficulties with both motion control and filtering. Nevertheless, we are proud to present the work, which cost us a lot of time and sleepless nights, even though we had hoped for a perfect result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdmclient import ClientAsync\n",
    "import cv2\n",
    "from scipy.spatial import distance as dist \n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import math\n",
    "%matplotlib qt\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import numpy as np\n",
    "client = ClientAsync()\n",
    "node = await client.wait_for_node()\n",
    "\n",
    "await node.lock()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FILTERING\n",
    "THYMIO_MMS = 0.12 # Thymio's unit to mm/s\n",
    "D_BASELINE = 100 # mm\n",
    "DELTA_T = 0.5 # s\n",
    "SIZE_PLOT = 110\n",
    "KIDNAP_THRESHOLD = 5\n",
    "\n",
    "KIDNAPPING_THRESHOLD = 3\n",
    "\n",
    "# MOTION CONTROL\n",
    "SUCCESS_THRESHOLD = 40 \n",
    "VELOCITY_THRESHOLD = 75 \n",
    "\n",
    "# VISION\n",
    "SCALING_FACTOR = 20/3\n",
    "\n",
    "# color filters\n",
    "HSV_RED_MIN = np.array([165, 30, 30])\n",
    "HSV_RED_MAX = np.array([180, 255, 255])\n",
    "\n",
    "HSV_ORANGE_MIN = np.array([0, 30, 30])\n",
    "HSV_ORANGE_MAX = np.array([15, 255, 255])\n",
    "\n",
    "HSV_GREEN_MIN = np.array([65, 40, 40])\n",
    "HSV_GREEN_MAX = np.array([85, 255, 255])\n",
    "\n",
    "HSV_BLUE_MIN = np.array([85, 100, 100])\n",
    "HSV_BLUE_MAX = np.array([110, 255, 255])\n",
    "\n",
    "TOLERANCE_HSV = np.array([8, 100, 100])\n",
    "\n",
    "# change those values with the camera \n",
    "RED_BGR = np.array([115, 95, 194], dtype = np.uint8)\n",
    "BLUE_BGR = np.array([134, 73, 12], dtype= np.uint8)\n",
    "GREEN_BGR = np.array([29, 72, 56], dtype = np.uint8)\n",
    "ORANGE_BGR = np.array([134, 73, 12], dtype = np.uint8)\n",
    "\n",
    "# camera and map parameters\n",
    "CAMERA_WIDTH = 1024\n",
    "CAMERA_HEIGHT = 768\n",
    "BIRD_WIDTH = 660\n",
    "BIRD_HEIGHT = 492\n",
    "MAP_WIDTH = 330\n",
    "MAP_HEIGHT = 246\n",
    "REAL_WIDTH = 1100\n",
    "REAL_HEIGHT = 820\n",
    "CAMERA_CORNERS = [[0, 0], [CAMERA_WIDTH, 0], [CAMERA_WIDTH, CAMERA_HEIGHT], [0, CAMERA_HEIGHT]]\n",
    "BIRD_CORNERS = [[0, 0], [BIRD_WIDTH, 0], [BIRD_WIDTH, BIRD_HEIGHT], [0, BIRD_HEIGHT]]\n",
    "MAP_CORNERS = np.array([[0, 0], [MAP_WIDTH, 0], [MAP_WIDTH, MAP_HEIGHT], [0, MAP_HEIGHT]], dtype=np.float32)\n",
    "\n",
    "# matching thresholds\n",
    "RES_THRESHOLD_BLACK = 0.84\n",
    "RES_THRESHOLD_RED = 0.4\n",
    "RES_THRESHOLD_GREEN = 0.3\n",
    "\n",
    "# binary thresholds\n",
    "BINARY_THRESHOLD_BLACK = 27\n",
    "BINARY_THRESHOLD_RED = 27\n",
    "BINARY_THRESHOLD_GREEN = 50\n",
    "BINARY_THRESHOLD_BLUE = 23\n",
    "\n",
    "OVERLAP_THRESHOLD = 0\n",
    "THYMIO_WIDTH = 29\n",
    "NOISE_WIDTH = 5\n",
    "TEMP_CENTER_Y = 53\n",
    "TEMP_CENTER_X = 69\n",
    "\n",
    "OBSTACLE_MAP_VALUE = -1\n",
    "BACKGROUND_MAP_VALUE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#templates\n",
    "template_cross = cv2.imread('/Users/tjga9/Documents/Tomas/EPFL/MA1/Basic of Mobile Robotics/Control your Thymio in Python/Control your Thymio in Python/template_cross_dll.jpg')\n",
    "\n",
    "method = eval('cv2.TM_CCORR_NORMED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_plot():\n",
    "    fig,ax = plt.subplots()\n",
    "    line, = ax.plot([], [], '--', label=\"Position with odometry\", color =\"black\")\n",
    "    ax.set_xlim(-SIZE_PLOT, SIZE_PLOT+100)\n",
    "    ax.set_ylim(-SIZE_PLOT, SIZE_PLOT)\n",
    "    ax.set_title(\"Real time Kalmann plot\")\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.legend()\n",
    "    ax.minorticks_on()\n",
    "    ax.grid(which='major', color=\"0.75\", linestyle='-')\n",
    "    #ax.grid(which='minor', color=\"0.75\", linestyle='--')\n",
    "    plt.rcParams.update({\n",
    "        \"text.usetex\": False,\n",
    "        \"font.family\": \"sans-serif\"\n",
    "    })\n",
    "\n",
    "    return fig, ax, line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_map(map_grid, path, start, goal):\n",
    "    cmap = ListedColormap(['white', 'black', 'blue', 'green', 'red', 'grey'])\n",
    "    map_display = np.zeros_like(map_grid, dtype=object)\n",
    "\n",
    "    # Assign colors based on the map grid values\n",
    "    map_display[map_grid == -1] = 'black'  # Obstacles\n",
    "    map_display[map_grid == 0] = 'white'   # Free space\n",
    "\n",
    "    # for position in explored:\n",
    "    #     if map_display[tuple(position)] == 'white':\n",
    "    #         map_display[tuple(position)] = 'grey'  # Explored cells\n",
    "\n",
    "    # Visualize the path\n",
    "    for position in path:\n",
    "        if map_display[position[0], position[1]] in ['white', 'grey']:\n",
    "            map_display[position[0], position[1]] = 'blue'  # Path\n",
    "\n",
    "    # map_display[5, 3] = 'yellow' # Weighted cell\n",
    "    map_display[start[0], start[1]] = 'green'  # Start\n",
    "    map_display[goal[0], goal[1]] = 'red'      # Goal\n",
    "\n",
    "    # Convert color names to numbers for plotting\n",
    "    color_mapping = {'white': 0, 'black': 1, 'blue': 2, 'green': 3, 'red': 4, 'grey': 5}\n",
    "    map_numeric_display = np.vectorize(color_mapping.get)(map_display)\n",
    "    fig, ax = plt.subplots(figsize=(6, 7))\n",
    "    ax.imshow(map_numeric_display, cmap=cmap)\n",
    "    ax.set_xticks(np.arange(-0.5, map_grid.shape[1], 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-0.5, map_grid.shape[0], 1), minor=True)\n",
    "    ax.grid(which='minor', color='gray', linestyle='-', linewidth=0.5)\n",
    "    ax.tick_params(which='both', bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thymio_transform_pose(pose, start): # from (x, y)_v to (x, y)_t \n",
    "    start_x, start_y = start\n",
    " \n",
    "    new_x = (pose[1] - start_y)\n",
    "    new_y = -(pose[0] - start_x)\n",
    "    \n",
    "    return new_x, new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_angle(angle):  # -π to π\n",
    "    normalized_angle = (angle + np.pi) % (2 * np.pi) - np.pi\n",
    "    return normalized_angle\n",
    "\n",
    "# def normalize_angle(angle_radians):\n",
    "#     # Normalization between -pi and pi\n",
    "#     pi = np.pi\n",
    "#     if angle_radians >= pi:\n",
    "#         angle_radians -= pi\n",
    "#     elif angle_radians < -pi:\n",
    "#         angle_radians += pi\n",
    "#     return angle_radians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_angle_full(angle_radians):\n",
    "    # Normalization between -2pi and 2pi\n",
    "    two_pi = 2*np.pi\n",
    "    if angle_radians >= two_pi:\n",
    "        angle_radians -= two_pi\n",
    "    elif angle_radians < -two_pi:\n",
    "        angle_radians += two_pi\n",
    "    return angle_radians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.0\n"
     ]
    }
   ],
   "source": [
    "print(np.rad2deg(normalize_angle(np.deg2rad(445))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motors(left, right):\n",
    "    return {\n",
    "        \"motor.left.target\": [left],\n",
    "        \"motor.right.target\": [right],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vision Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_corners = CAMERA_CORNERS #variable that will be updated each time\n",
    "is_cam_obstructed = False\n",
    "map = np.zeros((BIRD_HEIGHT, BIRD_WIDTH))\n",
    "bird_image = np.zeros((BIRD_HEIGHT, BIRD_WIDTH))\n",
    "hsv_img = np.zeros((BIRD_HEIGHT, BIRD_WIDTH, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_to_hsv(image):\n",
    "\t\"\"\"Filters the image from BGR colorspace to HSV colorspace\"\"\"\n",
    "\tfiltered_img = cv2.GaussianBlur(image,(5,5),1)\n",
    "    \n",
    "    # Convert BGR to HSV\n",
    "\thsv_img = cv2.cvtColor(filtered_img, cv2.COLOR_BGR2HSV)\n",
    "\treturn hsv_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_hsv_to_binary(hsv_img, bgr_color, binary_threshold):\n",
    "\t\"\"\"filters the color of an hsv image to a binary image.\n",
    "\tArguments:\n",
    "\t\thsv img : image in the hsv colorspace.\n",
    "\t\tbgr_color : color to filter in the bgr colorspace.\n",
    "\t\tbinary threshold : value btw 0 and 255 for binary filter.\n",
    "\t\n",
    "\tReturns:\n",
    "\t\timage in the binary colorspace.\"\"\"\n",
    "\thsv_min, hsv_max = band_pass_hsv(bgr_color)\n",
    "\tmask = cv2.inRange(hsv_img, hsv_min, hsv_max)\n",
    "\toutput = cv2.bitwise_and(hsv_img,hsv_img, mask= mask)\n",
    "\tgrayscale = output[:, :, 2]\n",
    "\t#convert to binary\n",
    "\tthreshold = binary_threshold\n",
    "\tret, bw = cv2.threshold(grayscale, threshold, 255, cv2.THRESH_BINARY)\n",
    "\treturn bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_grayscale(img):\n",
    "\t\"given image in bgr colorspace, convert it to grayscale then convert it to binary\"\n",
    "\t#convert to grayscale both image and template\n",
    "\timg_grayscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\t#convert to binary both image and template\n",
    "\tthreshold = BINARY_THRESHOLD_BLACK\n",
    "\tret, image_binary = cv2.threshold(img_grayscale, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\treturn image_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_back_coord(pose, start):\n",
    "    #pose is in (x, y) of thymio ref, start is (y, x) in matrix ref, converts to (x,y) to feed to opencv\n",
    "    start_y, start_x = start\n",
    "    new_x = pose[0] + start_x\n",
    "    new_y = -pose[1] + start_y\n",
    "\n",
    "    return np.array([new_x, new_y], dtype= int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_path(image, path, start):\n",
    "    #normalize coordinates ? we project onto an image twice bigger than our coord -> need to double the coord\n",
    "    print(\"SearchStart\", start)\n",
    "    previous = transform_back_coord(path[0], start)*2\n",
    "    print(\"previous\", previous)\n",
    "    for i in range(1, len(path)):\n",
    "        print(\"i\", i)\n",
    "        current = transform_back_coord(path[i], start)*2\n",
    "        print(\"current\", current)\n",
    "        print(\"previous\", previous)\n",
    "        cv2.line(image, previous, current, (0, 0, 255), 3)\n",
    "        previous = current\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_kalman(image, mean, spread, start):\n",
    "    \"\"\"Shows the estimation of the kalman filter on the image.\n",
    "    Arguments:\n",
    "        image : image to show the kalman filter on.\n",
    "        mean : mean (x, y, theta) of the kalman filter in mm.\n",
    "        spread : variance matrix of the Kalman Filter.\n",
    "        start : start position in numpy array coordinates.\n",
    "    Returns:\n",
    "        image : annotated image\"\"\"\n",
    "    #mean : result from filter : x, y, theta in pixels with reference of the thymio\n",
    "    #spread : spread in x, spread in y that are in mm\n",
    "    \n",
    "    spread = (int(spread[0, 0]), int(spread[1, 1]))\n",
    "    spread = (spread[0]*3//5, spread[1]*3//5)\n",
    "    angle = np.rad2deg(mean[2])\n",
    "    start = np.array(start)*2 \n",
    "    pose = (mean[0]*2, mean[1]*2) #multiply by 2 bc the mean of thymio is a map position and image shown is twice bigger than the map\n",
    "    if spread[0] == 0:\n",
    "        spread = (1, spread[1])\n",
    "    if spread[1] == 0:\n",
    "        spread = (spread[0], 1)    \n",
    "    center = transform_back_coord(pose, start)\n",
    "    \n",
    "    cv2.ellipse(image, center, spread[::-1], angle, 0, 360, (0, 255, 0), 1)\n",
    "    #spread[::-1] because we want variance in y first\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_grayscale(img):\n",
    "\t\"given image in bgr colorspace, convert it to grayscale then convert it to binary\"\n",
    "\t#convert to grayscale both image and template\n",
    "\timg_grayscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\t#convert to binary both image and template\n",
    "\tthreshold = BINARY_THRESHOLD_BLACK\n",
    "\tret, image_binary = cv2.threshold(img_grayscale, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\treturn image_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "\t\"\"\"Makes sure to only have one set of coordinate per cross to find the corners of the map (from pyImageSearch)\"\"\"\n",
    "\t# if there are no boxes, return an empty list\n",
    "\tif len(boxes) == 0:\n",
    "\t\treturn []\n",
    "\t# if the bounding boxes integers, convert them to floats --\n",
    "\t# this is important since we'll be doing a bunch of divisions\n",
    "\tif boxes.dtype.kind == \"i\":\n",
    "\t\tboxes = boxes.astype(\"float\")\n",
    "\t# initialize the list of picked indexes\t\n",
    "\tpick = []\n",
    "\t# grab the coordinates of the bounding boxes\n",
    "\tx1 = boxes[:,0]\n",
    "\ty1 = boxes[:,1]\n",
    "\tx2 = boxes[:,2]\n",
    "\ty2 = boxes[:,3]\n",
    "\t# compute the area of the bounding boxes and sort the bounding\n",
    "\t# boxes by the bottom-right y-coordinate of the bounding box\n",
    "\tarea = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "\tidxs = np.argsort(y2)\n",
    "\t# keep looping while some indexes still remain in the indexes\n",
    "\t# list\n",
    "\twhile len(idxs) > 0:\n",
    "\t\t# grab the last index in the indexes list and add the\n",
    "\t\t# index value to the list of picked indexes\n",
    "\t\tlast = len(idxs) - 1\n",
    "\t\ti = idxs[last]\n",
    "\t\tpick.append(i)\n",
    "\t\t# find the largest (x, y) coordinates for the start of\n",
    "\t\t# the bounding box and the smallest (x, y) coordinates\n",
    "\t\t# for the end of the bounding box\n",
    "\t\txx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "\t\tyy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "\t\txx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "\t\tyy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\t\t# compute the width and height of the bounding box\n",
    "\t\tw = np.maximum(0, xx2 - xx1 + 1)\n",
    "\t\th = np.maximum(0, yy2 - yy1 + 1)\n",
    "\t\t# compute the ratio of overlap\n",
    "\t\toverlap = (w * h) / area[idxs[:last]]\n",
    "\t\t# delete all indexes from the index list that have\n",
    "\t\tidxs = np.delete(idxs, np.concatenate(([last],\n",
    "\t\t\tnp.where(overlap > overlapThresh)[0])))\n",
    "\t# return only the bounding boxes that were picked using the\n",
    "\t# integer data type\n",
    "\treturn boxes[pick].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "\t\"\"\"Orders points of rectangle so that they are in the order : top_left, top_right, bottom_right, bottom_left (from pyImageSearch)\"\"\"\n",
    "\t# sort the points based on their x-coordinates\n",
    "\txSorted = pts[np.argsort(pts[:, 0]), :]\n",
    "\t# grab the left-most and right-most points from the sorted\n",
    "\t# x-roodinate points\n",
    "\tleftMost = xSorted[:2, :]\n",
    "\trightMost = xSorted[2:, :]\n",
    "\t# now, sort the left-most coordinates according to their\n",
    "\t# y-coordinates so we can grab the top-left and bottom-left\n",
    "\t# points, respectively\n",
    "\tleftMost = leftMost[np.argsort(leftMost[:, 1]), :]\n",
    "\t(tl, bl) = leftMost\n",
    "\t# now that we have the top-left coordinate, use it as an\n",
    "\t# anchor to calculate the Euclidean distance between the\n",
    "\t# top-left and right-most points; by the Pythagorean\n",
    "\t# theorem, the point with the largest distance will be\n",
    "\t# our bottom-right point\n",
    "\tD = dist.cdist(tl[np.newaxis], rightMost, \"euclidean\")[0]\n",
    "\t(br, tr) = rightMost[np.argsort(D)[::-1], :]\n",
    "\t# return the coordinates in top-left, top-right,\n",
    "\t# bottom-right, and bottom-left order\n",
    "\treturn np.array([tl, tr, br, bl], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_4_corners(img, template, method):\n",
    "\t\"\"\"finds the coordiantes of the corners of the map.\n",
    "\tArguments:\n",
    "\t\timg: image in the bgr color space.\t\n",
    "\t\ttemplate: image that has been filtered and is in the binary color space.\t\n",
    "\t\tmethod: cross-correlation method for template matching.\n",
    "\t\n",
    "\tReturns:\n",
    "\t\tis_found: boolean true if the corners have been found.\n",
    "\t\tcross_points: positions on the img of the corners\n",
    "\t\"\"\"\n",
    "\tis_found = False\n",
    "\t\n",
    "\t#filter the image\n",
    "\tfiltered_img = cv2.GaussianBlur(img,(5,5), 1)\n",
    "\t\n",
    "\t#convert image and template to binary\n",
    "\timage_binary = filter_grayscale(filtered_img)\n",
    "\ttemplate_binary = filter_grayscale(template)\n",
    "\t\n",
    "\t#cv2.imshow(\"binary of black\", image_binary)\n",
    "\t#get template dimensions\n",
    "\tc, w, h  = template.shape[::-1]\n",
    "\t#print(template.shape[::-1])\n",
    "\t\n",
    "\t#match template to image\n",
    "\tres = cv2.matchTemplate(image_binary,template_binary,method)\n",
    "\t(yCoords, xCoords) = np.where(res >= RES_THRESHOLD_BLACK)\n",
    "\n",
    "\n",
    "\t# initialize our list of rectangles\n",
    "\trects = []\n",
    "\t# loop over the starting (x, y)-coordinates again\n",
    "\tfor (x, y) in zip(xCoords, yCoords):\n",
    "\t\t# update our list of rectangles\n",
    "\t\trects.append((x, y, x + w, y + h))\n",
    "\t\n",
    "\t# apply non-maxima suppression to the rectangles\n",
    "\tpick = non_max_suppression_fast(np.array(rects), OVERLAP_THRESHOLD)\n",
    "\t#print(\"[INFO] {} matched locations after NMS\".format(len(pick)))\n",
    "\t\n",
    "\t#create a list of centers of the rectangles\n",
    "\tcross_points = []\n",
    "\tfor (startX, startY, endX, endY) in pick:\n",
    "\t    # draw the bounding box on the image\n",
    "\t\tcv2.rectangle(image_binary, (startX, startY), (endX, endY), (0, 0, 255), 3)\n",
    "\t\tcross_points.append([int((startX+endX)/2), int((startY+ endY)/2)]) \n",
    "\n",
    "\t#cv2.imshow(\"binary of black\", image_binary)\n",
    "\t#cv2.imshow(\"template\", template_binary)\n",
    "\n",
    "\tif (len(pick) == 4) :\n",
    "\t\tis_found = True\n",
    "\t\n",
    "\tcross_points = np.array(cross_points)\n",
    "\tcv2.imwrite(\"template_cross_binary.png\", image_binary)\n",
    "\t\n",
    "\treturn is_found, cross_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_image(image, template, method, old_corners):\n",
    "\t\"\"\"Transforms the camera image to a map bird's eye view with only the map.\n",
    "\tArguments:\n",
    "\t\timage: image of the camera in the bgr colorspace.\n",
    "\t\ttemplate: template of the cross.\n",
    "\t\tmethod: cross-correlation method.\n",
    "\t\told_corners: corners found previously by the function.\n",
    "\tReturns:\n",
    "\t\tis_found: boolean true if corners have been found.\n",
    "\t\tbird_image: projected image of the camera.\n",
    "\t\tmethod: cross correlation method for matchTemplate.\n",
    "\t\told_corners: corners found previously.\"\"\"\n",
    "\tis_found, cross_points = find_4_corners(image, template, method)\n",
    "\t\n",
    "\tif is_found:\n",
    "\t\tordered_crosses = order_points(cross_points)\n",
    "\t\t#store corners positions in case we have a frame where we don't see them anymore\n",
    "\t\told_corners = ordered_crosses\n",
    "\telse : \n",
    "\t\t#will become the last found corners, \n",
    "\t\tordered_crosses = old_corners\n",
    "\n",
    "\tordered_crosses = np.float32(ordered_crosses)\n",
    "\tbird_corners = np.float32(BIRD_CORNERS)\n",
    "\n",
    "\tmatrix = cv2.getPerspectiveTransform(ordered_crosses, bird_corners)\n",
    "\tbird_image = cv2.warpPerspective(image, matrix, (BIRD_WIDTH, BIRD_HEIGHT))\n",
    "\n",
    "\treturn is_found, bird_image, old_corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_obstacles(hsv_image):\n",
    "\t\"\"\"Finds the obstacles (blue parts) on the map and put them on the map\"\"\"\n",
    "\t#filter the orange color\n",
    "\thsv_min, hsv_max = band_pass_hsv(BLUE_BGR)\n",
    "\tmask = cv2.inRange(hsv_image, HSV_BLUE_MIN, HSV_BLUE_MAX)\n",
    "\toutput = cv2.bitwise_and(hsv_image,hsv_image, mask= mask)\n",
    "\t#cv2.imshow(\"output of blue filter\", output)\n",
    "\t#convert map to binary (0 = no obstacle, 1 = obstacle)\n",
    "\toutput_gray = output[:, :, 2]\n",
    "\t\n",
    "\tthreshold = BINARY_THRESHOLD_BLUE\n",
    "\tret, map = cv2.threshold(output_gray, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\t#map[map==255] = OBSTACLE_MAP_VALUE\n",
    "\treturn map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilate_obstacles(map, width):\n",
    "\t\"\"\"Dilates the obstacles to approximate the size of the thymio to one pixel.\n",
    "\tArguments:\n",
    "\t\tmap: image of 0 (background) and 1 (obstacles).\n",
    "\t\twidth: width of dilation of the obstacles.\n",
    "\tReturns:\n",
    "\t\tdilated_img: image with dilated obstacles.\"\"\"\n",
    "\n",
    "\tdilation_shape = cv2.MORPH_RECT\n",
    "\tkernel = cv2.getStructuringElement(dilation_shape, (2*width + 1, 2*width + 1), (width, width))\n",
    "\teroded_image = cv2.erode(map, kernel, iterations = 1)\n",
    "\tdilated_img = cv2.dilate(eroded_image, kernel, iterations = 2)\n",
    "\n",
    "\treturn dilated_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_map_borders(map, width):\n",
    "\t\"\"\"put the borders of the map as obstacles\"\"\"\n",
    "\tmap[0:width, :MAP_WIDTH] = 255\n",
    "\tmap[:MAP_HEIGHT, MAP_WIDTH-width:MAP_WIDTH] = 255\n",
    "\tmap[MAP_HEIGHT-width: MAP_HEIGHT, :MAP_WIDTH] = 255\n",
    "\tmap[:MAP_HEIGHT, 0:width] = 255\n",
    "\treturn map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_map(hsv_image):\n",
    "\t\"\"\"take the bird's eye image and convert it to a map, without the goal coordinates.\n",
    "\tArguments:\n",
    "\t\thsv_image: image in the hsv colorspace.\n",
    "\tReturns:\n",
    "\t\tmap in the binary colorspace.\"\"\"\n",
    "\t#projects map to smaller array\n",
    "\tbird_corners = np.array(BIRD_CORNERS, dtype = np.float32)\n",
    "\tmap_corners = np.array(MAP_CORNERS, dtype = np.float32)\n",
    "\tmatrix = cv2.getPerspectiveTransform(bird_corners, map_corners)\n",
    "\tbird_image = cv2.warpPerspective(hsv_image, matrix, (MAP_WIDTH, MAP_HEIGHT))\n",
    "\t\n",
    "\tobstacles = create_obstacles(bird_image)\n",
    "\t\n",
    "\tdilated_map = dilate_obstacles(obstacles, THYMIO_WIDTH)\n",
    "\tcv2.imwrite(\"map_inside_createMap.jpg\", dilated_map)\n",
    "\tmap = create_map_borders(dilated_map, THYMIO_WIDTH)\n",
    "\t#map[map == 255] = OBSTACLE_MAP_VALUE\n",
    "\treturn map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_goal(hsv_img):\n",
    "\t\"\"\"Finds coordinates of goal.\n",
    "\tArguments:\n",
    "\t\tbw: image in the binary color space.\t\n",
    "\t\ttemplate: image that has been filtered and is in the binary color space (1 dim).\n",
    "\t\tmethod: cross-correlation method for template matching.\n",
    "\tReturns:\n",
    "\t\tis_found: boolean true if goal has been found.\n",
    "\t\tposition: position (y, x) in array coordinates of the goal.\n",
    "\t\t\n",
    "\t\"\"\"\n",
    "\tis_found = False\n",
    "\tmask = cv2.inRange(hsv_img, HSV_GREEN_MIN, HSV_GREEN_MAX)\n",
    "\toutput = cv2.bitwise_and(hsv_img,hsv_img, mask= mask)\n",
    "\t#cv2.imshow(\"green banddpass\", output)\n",
    "\tgrayscale = output[:, :, 2]\n",
    "\t#convert to binary\n",
    "\tthreshold = BINARY_THRESHOLD_GREEN\n",
    "\tret, bw = cv2.threshold(grayscale, threshold, 255, cv2.THRESH_BINARY)\n",
    "\t\t\n",
    "\t#cv2.imshow(\"green filter\", bw)\n",
    "\t#cv2.imwrite(\"red_filter.jpg\", bw)\n",
    "\t\n",
    "\t#find location of thymio\n",
    "\tcontours, hierarchy  = cv2.findContours(bw, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\t#print(len(contours), \"elements found\")\n",
    "\tif len(contours) != 0:\n",
    "\t\t#if contour detected, keep the biggest one (most likely the thymio)\n",
    "\t\tcontours = sorted(contours, key = cv2.contourArea, reverse = True)\n",
    "\t\tcontour = contours[0]\n",
    "\n",
    "\t\tcontour_threshold = 30 #detect if contour found is too small\n",
    "\t\tM = cv2.moments(contour)\n",
    "\t\tif (M[\"m00\"] != 0) and (cv2.contourArea(contour) >= contour_threshold) :\n",
    "\t\t\tcX = int(M[\"m10\"]/M[\"m00\"])\n",
    "\t\t\tcY = int(M[\"m01\"]/M[\"m00\"])\n",
    "\t\t\tis_found = True\n",
    "\t\t\tposition = (cY//2, cX//2)\n",
    "\t\telse :\n",
    "\t\t\t#division by zero or no contour big enough found\n",
    "\t\t\t#print(M[\"m00\"], \"contour too small\") \n",
    "\t\t\tposition = (0, 0)\n",
    "\t\t\tis_found = False\n",
    "\telse:\n",
    "\t\t#no contour found\n",
    "\t\t#print(\"no contours found\")\n",
    "\t\tposition = (0, 0)\n",
    "\t\tis_found = False\n",
    "\t\n",
    "\treturn is_found, position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_l_thymio(bw):\n",
    "\t\"\"\"Finds coordinates of thymio.\n",
    "\tArguments:\n",
    "\t\tbw: image in the binary colorspace.\n",
    "\tReturns:\n",
    "\t\tis_found: boolean true if thymio has been found.\n",
    "\t\tposition: position (x, y) with x, y distances from top left corner\n",
    "\t\tangle: angle of the thymio in radians in [-pi, pi].\n",
    "\t\"\"\"\n",
    "\tis_found = False\n",
    "\n",
    "\t#find location of thymio\n",
    "\tcontours, hierarchy  = cv2.findContours(bw, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\t#print(len(contours), \"elements found\")\n",
    "\tif len(contours) >= 2:\n",
    "\t\t#if contour detected, keep the biggest one (most likely the thymio)\n",
    "\t\tcontours = sorted(contours, key = cv2.contourArea, reverse = True)\n",
    "\t\tbig_circle = contours[0]\n",
    "\t\tsmall_circle = contours[1]\n",
    "\n",
    "\t\tcontour_threshold = 10 #detect if contour found is too small\n",
    "\t\tM_big = cv2.moments(big_circle)\n",
    "\t\tM_small = cv2.moments(small_circle)\n",
    "\t\tif (M_big[\"m00\"] != 0) and (M_small[\"m00\"] != 0) and (cv2.contourArea(big_circle) >= contour_threshold) and (cv2.contourArea(small_circle) >= contour_threshold):\n",
    "\t\t\tcX_big = int(M_big[\"m10\"]/M_big[\"m00\"])\n",
    "\t\t\tcY_big = int(M_big[\"m01\"]/M_big[\"m00\"])\n",
    "\t\t\tcX_small = int(M_small[\"m10\"]/M_small[\"m00\"])\n",
    "\t\t\tcY_small = int(M_small[\"m01\"]/M_small[\"m00\"])\n",
    "\t\t\tis_found = True\n",
    "\t\t\tposition = ((cX_big + cX_small)//4, (cY_big + cY_small)//4)\n",
    "\t\t\tdelta_x = cX_big - cX_small\n",
    "\t\t\tdelta_y = cY_big - cY_small\n",
    "\t\t\tangle = -(np.arctan2(delta_y, delta_x))\n",
    "\t\telse :\n",
    "\t\t\t#division by zero or no contour big enough found\n",
    "\t\t\t#print(M[\"m00\"], \"contour too small\") \n",
    "\t\t\tposition = (0, 0)\n",
    "\t\t\tis_found = False\n",
    "\t\t\tangle = 0\n",
    "\telse:\n",
    "\t\t#no contour found\n",
    "\t\t#print(\"no contours found\")\n",
    "\t\tposition = (0, 0)\n",
    "\t\tis_found = False\n",
    "\t\tangle = 0\n",
    "\t\t\n",
    "\treturn is_found, position, angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_camera_obstructed(image):\n",
    "    \"\"\"Given image return boolean true if the camera is obstructed\"\"\"\n",
    "    img_grayscale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\t#convert to binary both image and template\n",
    "    threshold = 150\n",
    "    \n",
    "    ret, image_binary = cv2.threshold(img_grayscale, threshold, 255, cv2.THRESH_BINARY)\n",
    "    zero_points = cv2.findNonZero(image_binary)\n",
    "    \n",
    "    if (zero_points is None) or (len(zero_points) < 200):\n",
    "        is_obstructed = True\n",
    "    else:\n",
    "        is_obstructed = False\n",
    "    return is_obstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_image(image, old_corners):\n",
    "    ordered_crosses = np.float32(old_corners)\n",
    "    bird_corners = np.float32(BIRD_CORNERS)\n",
    "    matrix = cv2.getPerspectiveTransform(ordered_crosses, bird_corners)\n",
    "    bird_image = cv2.warpPerspective(image, matrix, (BIRD_WIDTH, BIRD_HEIGHT))\n",
    "\n",
    "    return bird_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thymio_pose(bird_image):\n",
    "\t\"\"\"returns position and angle of thymio.\n",
    "\tArguments:\n",
    "\t\timage: bird's eye image in the bgr colorspace.\n",
    "\tReturns:\n",
    "\t\tis_found: boolean true if thymio has been found.\n",
    "\t\tposition: position (y, x) with x, y distances from top left corner.\n",
    "\t\tangle: angle of the thymio in radians in [-pi, pi].\"\"\"\n",
    "\thsv_img = filter_to_hsv(bird_image)\n",
    "\t#keep only red and filter to binary\n",
    "\tbw = filter_hsv_to_binary(hsv_img, RED_BGR, BINARY_THRESHOLD_RED) \n",
    "\n",
    "\tcv2.imwrite(\"hsv_image_fed_to_red_filter.jpg\", bw) #for debug, to get rid of?\n",
    "\tcv2.imwrite(\"bird_image.jpg\", bird_image)\n",
    "\t#find position of thymio\n",
    "\tis_found, position, angle = find_l_thymio(bw)\n",
    "\t\t\n",
    "\tposition = position[::-1]\n",
    "\t# print(\"position_thymio\", is_found, position, angle)\n",
    "\tprint('............................................')\n",
    "\t\n",
    "\treturn is_found, position, angle #for now, the position is a pixel location, will need to convert it later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_setup(cam):\n",
    "\t\"\"\"Initialise the vision, waits for the camera to calibrate and give essential informations.\n",
    "\tArguments:\n",
    "\t\tcam: camera opencv object.\n",
    "\tReturns:\n",
    "\t\tmap: array where background is zero and obstacles are -1.\n",
    "\t\tgoal_position: position (y, x) of the goal in array coordinates.\n",
    "\t\tthymio_position: position (y, x) of the thymio in array coordinates.\n",
    "\t\tangle: angle of the thymio in radians between [-pi, pi].\n",
    "\t\told_corners: last positions of the four corners of the map in the camera image.\"\"\"\n",
    "\t\n",
    "\t#set it for later\n",
    "\told_corners = CAMERA_CORNERS #variable that will be updated each time\n",
    "\tmap = np.zeros((BIRD_HEIGHT, BIRD_WIDTH))\n",
    "\tbird_image = np.zeros((BIRD_HEIGHT, BIRD_WIDTH))\n",
    "\thsv_img = np.zeros((BIRD_HEIGHT, BIRD_WIDTH, 3))\n",
    "\ti = 0\n",
    "\twhile i !=30:\n",
    "\t\ti +=1\n",
    "\t\tret, image = cam.read()\n",
    "\t\t\n",
    "\t\tis_thymio_found = False\n",
    "\t\tcorners_found, bird_image, old_corners = warp_image(image, template_cross, method, old_corners)\n",
    "\t\tbird_image_copy = bird_image.copy() #picture\n",
    "\t\t\n",
    "\t\tprint(\"corners found\", corners_found)\n",
    "\t\thsv_img = filter_to_hsv(bird_image)\n",
    "\t\tmap = create_map(hsv_img)\n",
    "\t\tcv2.imwrite(\"map_inside_init.jpg\", map)\n",
    "\t\tis_goal_found, goal_position = find_goal(hsv_img)\n",
    "\t\ttry:\n",
    "\t\t\tis_cam_obstructed, is_thymio_found, thymio_position, angle = get_thymio_pose(image, old_corners)\n",
    "\t\texcept:\n",
    "\t\t\tprint(\"Crashed avoided\")\n",
    "\n",
    "\t\tcv2.imshow(\"Bird's eye view\", bird_image)\n",
    "\n",
    "\t# Release the capture and writer objects\n",
    "\t\n",
    "\tcv2.destroyAllWindows()\n",
    "\tmap = np.float32(map)\n",
    "\tmap[map == 255] = -1\n",
    "\t\n",
    "\n",
    "\treturn map, goal_position, thymio_position, angle, old_corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set it for later\n",
    "old_corners = CAMERA_CORNERS #variable that will be updated each time\n",
    "\n",
    "is_cam_setup = False\n",
    "is_cam_obstructed = False\n",
    "map = np.zeros((BIRD_HEIGHT, BIRD_WIDTH))\n",
    "bird_image = np.zeros((BIRD_HEIGHT, BIRD_WIDTH))\n",
    "hsv_img = np.zeros((BIRD_HEIGHT, BIRD_WIDTH, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path Planning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic(a, b):\n",
    "    # implement the manhattan distance heuristic\n",
    "    return abs(a[0] - b[0]) + abs(a[1] - b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_planning_a_star(map_grid, start, goal):\n",
    "    def lowest_f_costs(open_list, f_costs):\n",
    "        # identify the node in open_list wwith the lowest f_cost\n",
    "        lowest_idx = 0\n",
    "        for i in range(len(open_list)):\n",
    "            if f_costs[open_list[i]] < f_costs[open_list[lowest_idx]]:\n",
    "                lowest_idx = i\n",
    "        return lowest_idx\n",
    "        \n",
    "    # initialization\n",
    "    open_list = [start] # track unexplored nodes\n",
    "    explored = [] # track explored nodes\n",
    "    \n",
    "    came_from = {} # track parent node of each nodes\n",
    "    g_costs = {start: 0} # g_cost at each nodes\n",
    "    f_costs = {start: heuristic(start, goal)} # f_cost at each nodes = g_cost + heuristic\n",
    "    \n",
    "    operation_count = 0\n",
    "    \n",
    "    while open_list:\n",
    "        # pop the node with the lowest f_cost from the open set\n",
    "        current_idx = lowest_f_costs(open_list, f_costs)\n",
    "        current_pos = open_list.pop(current_idx)\n",
    "        explored.append(current_pos)\n",
    "\n",
    "        # reconstruct path\n",
    "        if current_pos == goal:\n",
    "            break\n",
    "        \n",
    "        # get the neighbors of the current node\n",
    "        neighbors = [\n",
    "            (current_pos[0] - 1, current_pos[1] - 1), # top-left\n",
    "            (current_pos[0] - 1, current_pos[1]),     # up\n",
    "            (current_pos[0] - 1, current_pos[1] + 1), # top-right\n",
    "            (current_pos[0], current_pos[1] - 1),     # left\n",
    "            (current_pos[0], current_pos[1] + 1),     # right\n",
    "            (current_pos[0] + 1, current_pos[1] - 1), # bottom-left\n",
    "            (current_pos[0] + 1, current_pos[1]),     # down\n",
    "            (current_pos[0] + 1, current_pos[1] + 1)  # bottom-right\n",
    "        ]\n",
    "\n",
    "        for neighbor in neighbors:\n",
    "            # check if neighbor is within bounds and not an obstacle\n",
    "            if (0 <= neighbor[0] < map_grid.shape[0]) and (0 <= neighbor[1] < map_grid.shape[1]):\n",
    "                if map_grid[neighbor[0], neighbor[1]] != -1 and neighbor not in explored:\n",
    "                    # calculate g_costs_updated, considering diagonal steps\n",
    "                    # probably add cost to g_scores if cells are near obstacles\n",
    "                    if (neighbor[0] != current_pos[0]) and (neighbor[1] != current_pos[1]):\n",
    "                        g_costs_updated = g_costs[current_pos] + np.sqrt(2)  # diagonal move cost\n",
    "                    else:\n",
    "                        g_costs_updated = g_costs[current_pos] + 1  # ddjacent move cost\n",
    "\n",
    "                    # record the best path\n",
    "                    if neighbor not in g_costs or g_costs_updated < g_costs[neighbor]:\n",
    "                        came_from[neighbor] = current_pos\n",
    "                        g_costs[neighbor] = g_costs_updated\n",
    "                        f_costs[neighbor] = g_costs_updated + heuristic(neighbor, goal)\n",
    "\n",
    "                        if neighbor not in open_list:\n",
    "                            open_list.append(neighbor)\n",
    "                        \n",
    "                        operation_count += 1\n",
    "\n",
    "    # reconstruct path\n",
    "    if current_pos == goal:\n",
    "        path = []\n",
    "        while current_pos in came_from:\n",
    "            path.append(current_pos)\n",
    "            current_pos = came_from[current_pos]\n",
    "        path.append(start)\n",
    "        path.reverse()\n",
    "        return path # in (x, y)_v\n",
    "    else:\n",
    "        # no path was found\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thymio_transform_path(path, start):\n",
    "    #transform the path to new reference with origin at starting point\n",
    "    start_x, start_y = start\n",
    " \n",
    "    path_transformed = []\n",
    "\n",
    "    for x, y in path:\n",
    "\n",
    "        new_x = (y - start_y)\n",
    "        new_y = -(x - start_x)\n",
    "\n",
    "        path_transformed.append((new_x, new_y))\n",
    "        \n",
    "    return path_transformed # in (x, y)_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_combining(path):\n",
    "    # initialize\n",
    "    path_translate = path\n",
    "    path_rotate = []\n",
    "    path_combined = []\n",
    "    \n",
    "    # check if the map has at least 2 points\n",
    "    if len(path) < 2:\n",
    "        return [] \n",
    "    \n",
    "    # calculate robot's orientation at each position\n",
    "    for i in range(len(path_translate) - 1):\n",
    "        dx = path_translate[i+1][0] - path_translate[i][0]\n",
    "        dy = path_translate[i+1][1] - path_translate[i][1]\n",
    "        \n",
    "        angle = np.arctan2(dy, dx) # rad\n",
    "        \n",
    "        path_rotate.append(angle)\n",
    "    \n",
    "    # generate final path with both positions and orientation\n",
    "    for i in range(len(path_translate) - 1):\n",
    "        x_coordinate = path_translate[i][0]\n",
    "        y_coordinate = path_translate[i][1]\n",
    "        angle = path_rotate[i]\n",
    "        \n",
    "        path_combined.append((x_coordinate, y_coordinate, angle))\n",
    "    \n",
    "    if path:\n",
    "        last_point = path[-1]\n",
    "        last_angle = path_rotate[-1] if path_rotate else 0  # default to 0 if no angles calculated\n",
    "        path_combined.append((last_point[0], last_point[1], last_angle))\n",
    "    \n",
    "    return path_combined # (x, y, theta_rad)_t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_finalizing(path, start, scale_factor = SCALING_FACTOR):\n",
    "    path = thymio_transform_path(path, start)\n",
    "    path = path_combining(path)\n",
    "    \n",
    "    path_final = [path[0]]\n",
    "    \n",
    "    # simplify the path into critical points\n",
    "    for pose in path[1:]:\n",
    "        if pose[2] != path_final[-1][2]:\n",
    "            path_final.append(pose)\n",
    "    \n",
    "    path_final.append(path[-1])\n",
    "\n",
    "    path = [(x * scale_factor, y * scale_factor, z) for x, y, z in path]     \n",
    "        \n",
    "    return path_final # (x, y, theta_rad)_t_reduced_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Avoidance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding local avoidance, we chose to use the Artificial Neural Network algorithm, utilizing horizontal proximity sensors. The weights were assigned based on the sensor responses, meaning that some sensors are less responsive than others. Additionally, a scaling factor was used, chosen empirically after several trials, along with a condition on the sensors to set a boolean to true if the robot detects an obstacle. The function's output provides the command for the motor, indicating how to rotate the wheels in order to avoid the obstacle, as well as the boolean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_neural = np.array([0,0])\n",
    "sensor = np.array([0,0,0,0,0,0,0])\n",
    "is_obstacle = False\n",
    "motor_target = [0,0]\n",
    "\n",
    "def local_avoidance(prox_horizontal):\n",
    "    global  motor_target, is_obstacle\n",
    "\n",
    "    #Weights\n",
    "    w_l = [10, 3 , 2, 1, 1,  1, 1]\n",
    "    w_r = [1, 1, 10,  3,  5, 1,  1]\n",
    "    \n",
    "\n",
    "    # Scale factors for sensors and constant factor\n",
    "    sensor_scale = 500\n",
    "    sensor = prox_horizontal\n",
    "    \n",
    "    for i in range(5):\n",
    "        \n",
    "        if sensor[0] == sensor[1] == sensor[2] == sensor[3] == sensor[4] == 0:\n",
    "            output_neural[0] = output_neural[1] = 0\n",
    "            is_obstacle = False\n",
    "        else:\n",
    "            is_obstacle = True\n",
    "            \n",
    "        # Get and scale inputs\n",
    "        sensor[i] = prox_horizontal[i] // sensor_scale\n",
    "        \n",
    "        # Compute outputs of neurons and set motor powers\n",
    "        output_neural[0] = output_neural[0] + sensor[i] * w_l[i] #left motor\n",
    "        output_neural[1] = output_neural[1] + sensor[i] * w_r[i] #right motor\n",
    "            \n",
    "    \n",
    "    # Set motor powers\n",
    "    motor_target [0] = output_neural[0] # motor left\n",
    "    motor_target [1] = output_neural[1] # motor right\n",
    "    \n",
    "    return motor_target, is_obstacle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kidnapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the kidnapping detection, we leveraged the IMU integrated into the robot as well as the two proximity sensors located at the back of the robot. Indeed, during a kidnapping event, the robot will experience acceleration along all axes. To make this function even more robust, we chose to use the proximity sensors, which, when the robot is picked up, will help complete the conditions to set the \"is_kidnapped\" boolean to true. This command will be returned upon the function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "kidnapped = False\n",
    "\n",
    "def kidnapping(acceleration, sensor):\n",
    "   global kidnapped\n",
    "\n",
    "   if (abs(acceleration[0]) > KIDNAPPING_THRESHOLD or abs(acceleration[1]) > KIDNAPPING_THRESHOLD) and (sensor[5] != 0 or sensor[6] != 0):\n",
    "      kidnapped = True\n",
    "      print('kidnapped: ', kidnapped)\n",
    "   else:\n",
    "      kidnapped = False\n",
    "      print('kidnapped: ', kidnapped)\n",
    "   \n",
    "   return kidnapped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The state variable for the Kalman filter are \n",
    "\n",
    "\\begin{cases}\n",
    "   x_{+} = x_{0} + v*\\Delta_{t}*cos(\\theta)\\\\\n",
    "   y_{+} = y_{0} + v*\\Delta_{t}*sin(\\theta)\\\\\n",
    "   \\theta_{+} = \\theta_{0} + \\phi\\\\\n",
    "   v_{right}\\\\\n",
    "   v_{left}\n",
    "\\end{cases}\n",
    "\n",
    "This allow us to first calculate the Jacobian matrix. Furthermore, we distinguish between two cases: the first case occurs when the camera is obscured, in which only the left and right speed states are accessible. The second case applies when the camera is not hidden, and the vision data are used to calculate de filter.\n",
    "\n",
    "To determine the components of the process noise and measurement noise matrices, we conducted several experiments with the Thymio. For example, we instructed it to travel a certain distance for 10 seconds before stopping. We then measured the distance it covered. By repeating this experiment multiple times, we obtained a dataset with varying positions, from which we extracted  the variance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_est= y_est =  0 \n",
    "is_initialized = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La variance de la position est : 0.00017508650519031173\n",
      "La variance de l'angle est : 0.0009884083044982715\n",
      "La variance de la vitesse basé sur la position est : 0.017806122448979594\n",
      "La variance de la position basé sur l'odom est : 0.0006906666666666697\n",
      "La variance de la vitesse est : 0.19704374999999993\n",
      "La variance de l'angle basé sur l'odoom est : 0.0034459288888888853\n",
      "La variance de la position basé sur la vision est : 2.7744000000000093\n",
      "La variance de l'angle basé sur la vision est : 9.008999999999663e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_position = [1.85,1.83,1.86,1.87,1.84,1.87,1.85,1.84,1.83,1.85,1.84,1.83,1.85,1.87,1.85,1.86,1.84] #mm for 1step de 0.1s\n",
    "data_angle = [2.24,2.21,2.20,2.18,2.185,2.17,2.19,2.165,2.14,2.12,2.185,2.15,2.16,2.15,2.12,2.13,2.16] #rad for 1 step every 0.1s\n",
    "data_sp_based_pos = [18.5,18.3,18.6,18.7,18.4,18.7,18.5,18.4,18.3,18.5,18.7,18.5,18.6,18.4] #mm/s extracted from the position measured during 10s\n",
    "data_mean_speed_measured = np.array([51.5,60,56,52.5,49.5,56,51.5,45.5,53,51.5,53.5,59.5,51.5,49,55,49.5])*THYMIO_MMS # mm/s, for the R matrix \n",
    "data_pos_odom =[2.91,2.93,2.97,2.92,2.93,2.91,2.90,2.91,2.97,2.90,2.90,2.90,2.87,2.89,2.90] #mm every 0.1s for 10s\n",
    "data_angle_odom = [6.023,6.208,6.204,6.151,6.086,6.113,6.151,6.166,6.057,6.169,6.165,6.065,6.155,6.240,6.116]\n",
    "\n",
    "#vision value\n",
    "data_vision_position_x_y = [76.6, 80, 76.6, 76.6, 76.6, 80, 80, 76.6,76.6, 80]\n",
    "data_vision_angle = [6.248, 6.265, 6.248, 6.230, 6.248, 6.230, 6.248, 6.248, 6.248, 6.248]\n",
    "\n",
    "# Calcul de la moyenne et de l'écart-type\n",
    "#1\n",
    "mean_pos = 0 #np.mean(data_position)\n",
    "std_dev_pos = np.std(data_position)\n",
    "\n",
    "#2\n",
    "mean_angle = 0.3 #np.mean(data_angle)\n",
    "std_dev_angle = np.std(data_angle)\n",
    "\n",
    "#3\n",
    "mean_spd = np.mean(data_mean_speed_measured)\n",
    "std_dev_spd = np.std(data_mean_speed_measured)\n",
    "\n",
    "#4\n",
    "mean_spd_pos = np.mean(data_sp_based_pos)\n",
    "std_dev_spd_pos = np.std(data_sp_based_pos)\n",
    "\n",
    "#5\n",
    "mean_pos_odom = np.mean(data_pos_odom)\n",
    "std_pos_odom = np.std(data_pos_odom)\n",
    "\n",
    "#6\n",
    "mean_angle_odom = 0.30 #np.mean(data_angle_odom)\n",
    "std_angle_odom = np.std(data_angle_odom)\n",
    "\n",
    "#7\n",
    "mean_vision_position_x_y = 0 #np.mean(data_vision_position_x_y)\n",
    "std_vision_position_x_y = np.std(data_vision_position_x_y)\n",
    "\n",
    "#8\n",
    "mean_vision_angle = np.mean(data_vision_angle)\n",
    "std_vision_angle = np.std(data_vision_angle)\n",
    "\n",
    "\n",
    "x1 = np.linspace(mean_pos - 3*std_dev_pos, mean_pos + 3*std_dev_pos, 500)  # Intervalle autour de la moyenne\n",
    "y1 = (1 / (std_dev_pos * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x1 - mean_pos) / std_dev_pos) ** 2)\n",
    "\n",
    "x2 = np.linspace(mean_angle - 3*std_dev_angle, mean_angle + 3*std_dev_angle, 500)  # Intervalle autour de la moyenne\n",
    "y2 = (1 / (std_dev_angle * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x2 - mean_angle) / std_dev_angle) ** 2)\n",
    "\n",
    "x3 = np.linspace(mean_spd - 3*std_dev_spd, mean_spd + 3*std_dev_spd, 500)  # Intervalle autour de la moyenne\n",
    "y3 = (1 / (std_dev_spd * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x3 - mean_spd) / std_dev_spd) ** 2)\n",
    "\n",
    "x4 = np.linspace(mean_spd_pos - 3*std_dev_spd_pos , mean_spd_pos + 3*std_dev_spd_pos , 500)  # Intervalle autour de la moyenne\n",
    "y4 = (1 / (std_dev_spd_pos  * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x4 - mean_spd_pos) / std_dev_spd_pos ) ** 2)\n",
    "\n",
    "x5 = np.linspace(mean_pos_odom - 3*std_pos_odom , mean_pos_odom + 3*std_pos_odom , 500)  # Intervalle autour de la moyenne\n",
    "y5 = (1 / (std_pos_odom  * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x5 - mean_pos_odom) / std_pos_odom ) ** 2)\n",
    "\n",
    "x6 = np.linspace(mean_angle_odom - 3*std_angle_odom , mean_angle_odom + 3*std_angle_odom , 500)  # Intervalle autour de la moyenne\n",
    "y6 = (1 / (std_angle_odom  * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x6 - mean_angle_odom) / std_angle_odom ) ** 2)\n",
    "\n",
    "x7= np.linspace(mean_vision_position_x_y - 3*std_vision_position_x_y , mean_vision_position_x_y + 3*std_vision_position_x_y , 500)  # Intervalle autour de la moyenne\n",
    "y7 = (1 / (std_vision_position_x_y  * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x7 - mean_vision_position_x_y) / std_vision_position_x_y ) ** 2)\n",
    "\n",
    "x8= np.linspace(mean_vision_angle - 3*std_vision_angle , mean_vision_angle + 3*std_vision_angle , 500)  # Intervalle autour de la moyenne\n",
    "y8 = (1 / (std_vision_angle  * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x8 - mean_vision_angle) / std_vision_angle ) ** 2)\n",
    "\n",
    "#Valeur de la variance de la position \n",
    "variance_pos = np.var(data_position)\n",
    "\n",
    "variance_angle = np.var(data_angle)\n",
    "\n",
    "variance_speed = np.var(data_mean_speed_measured)\n",
    "\n",
    "variance_speed_pos = np.var(data_sp_based_pos)\n",
    "\n",
    "variance_pos_odom = np.var(data_pos_odom)\n",
    "\n",
    "variance_angle_odom = np.var(data_angle_odom)\n",
    "\n",
    "variance_position_vision = np.var(data_vision_position_x_y) \n",
    "\n",
    "variance_angle_vision = np.var(data_vision_angle)\n",
    "\n",
    "print(f\"La variance de la position est : {variance_pos}\")#q_x and q_y\n",
    "print(f\"La variance de l'angle est : {variance_angle}\")#q_theta\n",
    "print(f\"La variance de la vitesse basé sur la position est : {variance_speed_pos}\")#q_v_x and q_v_y\n",
    "\n",
    "print(f\"La variance de la position basé sur l'odom est : {variance_pos_odom}\") #R_x and R_y\n",
    "print(f\"La variance de la vitesse est : {variance_speed}\")#R_v_x and R_v_y\n",
    "print(f\"La variance de l'angle basé sur l'odoom est : {variance_angle_odom}\")#R_theta\n",
    "\n",
    "print(f\"La variance de la position basé sur la vision est : {variance_position_vision}\")#R_x_vision\n",
    "print(f\"La variance de l'angle basé sur la vision est : {variance_angle_vision}\")#R_angle_vision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "y1_normalized = y1 / max(y1)\n",
    "y2_normalized = y2 / max(y2)\n",
    "y3_normalized = y3 / max(y3)\n",
    "y4_normalized = y4 / max(y4)\n",
    "y5_normalized = y5 / max(y5)\n",
    "y6_normalized = y6 / max(y6)\n",
    "y7_normalized = y7 / max(y7)\n",
    "y8_normalized = y8 / max(y8)\n",
    "\n",
    "# Tracé des distributions sur le même graphique\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.xlim(-0.5, 0.5)\n",
    "\n",
    "# Ajout de chaque courbe au graphique avec normalisation\n",
    "plt.plot(x1, y1_normalized, label=\"Position (data_position)\", alpha=0.8)\n",
    "plt.plot(x2, y2_normalized, label=\"Angle (data_angle)\", alpha=0.8)\n",
    "# plt.plot(x3, y3_normalized, label=\"Vitesse mesurée (data_mean_speed_measured)\", alpha=0.8)\n",
    "# plt.plot(x4, y4_normalized, label=\"Vitesse basée sur la position (data_sp_based_pos)\", alpha=0.8)\n",
    "# plt.plot(x5, y5_normalized, label=\"Position (odométrie, data_pos_odom)\", alpha=0.8)\n",
    "plt.plot(x6, y6_normalized, label=\"Angle (odométrie, data_angle_odom)\", alpha=0.8)\n",
    "plt.plot(x7, y7_normalized, label=\"Position (vision, data_vision_position_x_y)\", alpha=0.8)\n",
    "# plt.plot(x8, y8_normalized, label=\"Angle (vision, data_vision_angle)\", alpha=0.8)\n",
    "\n",
    "# Configuration des axes et de la légende\n",
    "plt.title(\"Distributions normalisées des données avec courbes gaussiennes\", fontsize=16)\n",
    "plt.xlabel(\"Valeurs normalisées\", fontsize=14)\n",
    "plt.ylabel(\"Densité de probabilité relative\", fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "\n",
    "# Affichage du graphique\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odometrie(x_prev,y_prev,theta_prev,motor_r,motor_l):\n",
    "    \"\"\"\n",
    "    Allows calculating the states x, y, theta based on the speeds of the left and right wheels\n",
    "    Parameter v: linear motion\n",
    "    Parameter w: anglular motion\n",
    "    Parameter D_BASELINE: distance of the two wheels \n",
    "    \"\"\"\n",
    "   \n",
    "    v = (motor_r + motor_l)*THYMIO_MMS/2\n",
    "    w = (motor_r - motor_l)*THYMIO_MMS\n",
    "\n",
    "    theta = theta_prev  + w*DELTA_T/D_BASELINE\n",
    "    \n",
    "    x = x_prev + v*DELTA_T*np.cos(theta_prev)\n",
    "    y = y_prev + v*DELTA_T*np.sin(theta_prev)\n",
    "\n",
    "    return x,y, theta , motor_r, motor_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jacobien(theta, v_right, v_left): \n",
    "    \"\"\"\n",
    "    Computes the Jacobian matrix for the Kalman filter, \n",
    "    \"\"\"\n",
    "    alpha = THYMIO_MMS * (v_right + v_left) / 2\n",
    "    beta = THYMIO_MMS * (v_right - v_left) / D_BASELINE\n",
    "\n",
    "    A = - (alpha * DELTA_T * np.sin(theta + DELTA_T * beta))\n",
    "    B = (1/2) * DELTA_T * np.cos(theta + DELTA_T * beta) - (alpha * (1 / D_BASELINE) * DELTA_T**2 * np.sin(theta + DELTA_T * beta))\n",
    "    C = (1/2) * DELTA_T * np.cos(theta + DELTA_T * beta) + (alpha * (1 / D_BASELINE) * DELTA_T**2 * np.cos(theta + DELTA_T * beta))\n",
    "    D = alpha * DELTA_T * np.cos(theta + DELTA_T * beta)\n",
    "    E = (1/2) * DELTA_T * np.sin(theta + DELTA_T * beta) + (alpha * (1 / D_BASELINE) * DELTA_T**2 * np.cos(theta + DELTA_T * beta))\n",
    "    F = (1/2) * DELTA_T * np.sin(theta + DELTA_T * beta) - (alpha * (1 / D_BASELINE) * DELTA_T**2 * np.cos(theta + DELTA_T * beta))\n",
    "    G = DELTA_T/D_BASELINE\n",
    "    H = -DELTA_T/D_BASELINE\n",
    "    \n",
    "    J = np.array([[1, 0, A, B, C],\n",
    "                  [0, 1, D, E, F],\n",
    "                  [0, 0, 1, G, H],\n",
    "                  [0, 0, 0, 1, 0],\n",
    "                  [0, 0, 0, 0, 1]])\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "'code inspired by the course of Prof. Mondada, course 7-8, p.40, 2024'\n",
    "q_x = q_y = 2.74e-1\n",
    "q_theta = 1.24e-1\n",
    "q_vx = q_vy = 1.52\n",
    "x_odom = y_odom = 0\n",
    "\n",
    "def EKF(x, y, theta, v_r, v_l, mu_pred_prev, u_state_prev, sigma_pred_prev, R ,C, not_vision):\n",
    "    \"\"\"\n",
    "    The Extended Kalman Filter is used to filter and fuse the data from the sensors\n",
    "    Parameter Q: Process noise matrix\n",
    "    Parameter R: Measurement noise matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    A = np.array([[1, 0, 0, 0, 0],\n",
    "             [0, 1, 0, 0, 0],\n",
    "             [0, 0, 1, 0, 0],\n",
    "             [0, 0, 0, 0, 0],\n",
    "             [0, 0, 0, 0, 0]])\n",
    "    \n",
    "    Q = np.array([\n",
    "            [q_x,0,0,0,0],\n",
    "            [0,q_y,0,0,0],\n",
    "            [0,0,q_theta,0,0],\n",
    "            [0,0,0,q_vx,0],\n",
    "            [0,0,0,0,q_vy]\n",
    "            ])\n",
    "\n",
    "    B = np.array([[DELTA_T*THYMIO_MMS*np.cos(theta)/2, DELTA_T*THYMIO_MMS*np.cos(theta)/2],\n",
    "              [DELTA_T*THYMIO_MMS*np.sin(theta)/2, DELTA_T*THYMIO_MMS*np.sin(theta)/2],\n",
    "              [DELTA_T*THYMIO_MMS/D_BASELINE, -DELTA_T*THYMIO_MMS//D_BASELINE],\n",
    "              [1, 0],\n",
    "              [0, 1]])\n",
    "    \n",
    "    # Prediction Phase\n",
    "    mu_pred = np.dot(A,mu_pred_prev) + np.dot(B,u_state_prev)\n",
    "    sigma_pred = np.matmul(np.matmul(Jacobien(theta, v_r, v_l),sigma_pred_prev),np.transpose(Jacobien(theta, v_r, v_l))) + Q \n",
    "\n",
    "    # Innovation Phase\n",
    "    y = np.array([[x],[y],[theta],[v_r],[v_l]])\n",
    "        \n",
    "    inno = y -np.dot(C, mu_pred)\n",
    "\n",
    "    S = np.matmul(np.matmul(C,sigma_pred),np.transpose(C)) + R \n",
    "\n",
    "    K_gain = np.matmul(np.matmul(sigma_pred,np.transpose(C)),np.linalg.inv(S))\n",
    "\n",
    "    # Posteriori\n",
    "\n",
    "    mu_post = mu_pred + np.dot(K_gain,inno)\n",
    "    sigma_post = np.matmul(np.subtract(np.eye(5),np.matmul(K_gain,C)),sigma_pred)\n",
    "\n",
    "    return mu_post, sigma_post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motion Control Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "motor_speed = 100\n",
    "count_control = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def p_control(angle_error, kp, motor_speed):\n",
    "#     p_correction = kp * abs(angle_error)\n",
    "\n",
    "#     if angle_error < 0.0:\n",
    "#         motor_left = int(motor_speed + p_correction)\n",
    "#         motor_right = int(motor_speed - p_correction)\n",
    "#     else:\n",
    "#         motor_left = int(motor_speed - p_correction)\n",
    "#         motor_right = int(motor_speed + p_correction)\n",
    "    \n",
    "#     return motor_left, motor_right\n",
    "\n",
    "def p_control(angle_error, kp, motor_speed):\n",
    "    if abs(angle_error) < np.pi:\n",
    "        p_correction = kp * abs(angle_error) \n",
    "        if angle_error < 0.0:\n",
    "           motor_left = int(motor_speed + p_correction)\n",
    "           motor_right = int(motor_speed - p_correction)\n",
    "        else:\n",
    "           motor_left = int(motor_speed - p_correction)\n",
    "           motor_right = int(motor_speed + p_correction)\n",
    "    else:\n",
    "        p_correction = kp * abs(2 * np.pi - angle_error)\n",
    "        if angle_error > 0.0:\n",
    "           motor_left = int(motor_speed + p_correction)\n",
    "           motor_right = int(motor_speed - p_correction)\n",
    "        else:\n",
    "           motor_left = int(motor_speed - p_correction)\n",
    "           motor_right = int(motor_speed + p_correction)\n",
    "    \n",
    "    return motor_left, motor_right "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_control = 0\n",
    "right_speed = left_speed = 0\n",
    "\n",
    "async def motion_control(pose, path):\n",
    "   \n",
    "    global count_control, left_speed, right_speed\n",
    "\n",
    "    if count_control < len(path): # motion control \n",
    "        sub_goal = path[count_control]\n",
    "        \n",
    "        dist_x = sub_goal[0] - pose[0] # distance in x-direction\n",
    "        dist_y = sub_goal[1] - pose[1] # distance in y-direction\n",
    "        \n",
    "        angle_target = np.arctan2(dist_y, dist_x) # in (x, y, theta_rad)_t\n",
    "        # angle_robot = pose[2]\n",
    "        angle_robot = normalize_angle(pose[2]) # theta_filtered\n",
    "        # angle_robot = pose[2] # theta_filtered\n",
    "        # angle_error = normalize_angle(angle_target - angle_robot)\n",
    "        angle_error = angle_target - angle_robot\n",
    "        \n",
    "        dist_to_goal = np.sqrt((dist_x)**2 + dist_y**2) # distance from current pose to subgoal\n",
    "        print('sub_goal_angle: ', np.rad2deg(sub_goal[2]), 'sub_goal: ', sub_goal)\n",
    "        \n",
    "\n",
    "        if sub_goal[0] == sub_goal[1] == 0 and abs(sub_goal[2] - angle_robot) > np.deg2rad(10):\n",
    "            left_speed, right_speed = p_control(sub_goal[2] - angle_robot, 25, motor_speed = 0)\n",
    "            await node.set_variables(motors(left_speed, right_speed))\n",
    "            print('left: ', left_speed, 'right: ', right_speed)\n",
    "            print('starting difference angle: ', np.rad2deg(sub_goal[2]) - np.rad2deg(angle_robot))\n",
    "\n",
    "        \n",
    "        elif dist_to_goal >= 20: # SUCCESS_THRESHOLD\n",
    "         \n",
    "\n",
    "            if dist_to_goal <= 40:\n",
    "                left_speed, right_speed = p_control(angle_error, 15, 40)\n",
    "                await node.set_variables(motors(left_speed, right_speed))\n",
    "                # print('pose_x_fil: ', pose[0], 'pose_y_fil: ', pose[1])\n",
    "                print('dist small', dist_to_goal)\n",
    "                print('angle target: ', np.rad2deg(angle_target))\n",
    "                # print('angle_robot: ', np.rad2deg(angle_robot))\n",
    "                # print('angle difference: ', np.rad2deg(angle_target - angle_robot))\n",
    "                print('angle error: ', np.rad2deg(angle_error))\n",
    "                print('left: ', left_speed, 'right: ', right_speed)\n",
    "                \n",
    "            else:\n",
    "                left_speed, right_speed = p_control(angle_error, 25, 75)\n",
    "                await node.set_variables(motors(left_speed, right_speed))\n",
    "                # print('pose_x_fil: ', pose[0], 'pose_y_fil: ', pose[1])\n",
    "                print('dist big', dist_to_goal) \n",
    "                print('angle target: ', np.rad2deg(angle_target))\n",
    "                # print('angle robot: ', np.rad2deg(angle_robot))\n",
    "                # print('angle difference: ', np.rad2deg(angle_target - angle_robot))\n",
    "                print('angle error: ', np.rad2deg(angle_error))\n",
    "                print('left: ', left_speed, 'right: ', right_speed)   \n",
    "            \n",
    "        else:\n",
    "            # print('goal reached')\n",
    "            # if abs(sub_goal[2] - angle_robot) > np.deg2rad(35):\n",
    "            #     left_speed, right_speed = p_control(sub_goal[2] - angle_robot, 30, motor_speed = 0) #if abs(left_speed) > 15 else 15\n",
    "            #     await node.set_variables(motors(left_speed, right_speed))\n",
    "            #     print('rotating')\n",
    "            #     print('to goal angle: ', np.rad2deg(angle_target))\n",
    "            #     print('angle_fil: ', np.rad2deg(angle_robot))\n",
    "            #     print('angle difference: ', np.rad2deg(angle_target - angle_robot))\n",
    "            #     #print('angle error: ', np.rad2deg(angle_error))\n",
    "            #     print('left: ', left_speed, 'right: ', right_speed)   \n",
    "            # else: \n",
    "            print('correction finished')\n",
    "            count_control += 1\n",
    "        print(sub_goal)\n",
    "        print('count: ', count_control)\n",
    "\n",
    "    else: \n",
    "        await node.set_variables(motors(0,0))\n",
    "\n",
    "    return left_speed, right_speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering Part\n",
    "x_odom_array = []\n",
    "y_odom_array = []\n",
    "\n",
    "\n",
    "sigma = np.zeros(5)\n",
    "x_kalman = []\n",
    "y_kalman = []\n",
    "\n",
    "#Initialisation des graphiques\n",
    "fig, ax, line = initialize_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corners found True\n",
      "corners found True\n",
      "corners found True\n",
      "corners found True\n",
      "corners found True\n",
      "corners found True\n",
      "corners found True\n",
      "corners found True\n",
      "corners found True\n",
      "corners found True\n",
      "corners found True\n",
      "corners found True\n",
      "corners found True\n",
      "corners found True\n",
      "corners found True\n",
      "corners found True\n",
      "corners found True\n",
      "corners found True\n",
      "corners found True\n",
      "corners found True\n",
      "corners found True\n",
      "corners found True\n",
      "corners found True\n",
      "corners found True\n",
      "corners found True\n",
      "corners found True\n",
      "corners found True\n",
      "corners found True\n",
      "corners found True\n",
      "corners found True\n",
      "path:  [(0.0, 0.0, -135.0), (-9.0, -9.0, 180.0), (-166.0, -9.0, -135.0), (-193.0, -36.0, -90.0), (-193.0, -99.0, -90.0)]\n",
      "theta vision init:  -2.443689830994736\n",
      "SearchStart (73, 256)\n",
      "previous [512 146]\n",
      "i 1\n",
      "current [494 164]\n",
      "previous [512 146]\n",
      "i 2\n",
      "current [180 164]\n",
      "previous [494 164]\n",
      "i 3\n",
      "current [126 218]\n",
      "previous [180 164]\n",
      "i 4\n",
      "current [126 344]\n",
      "previous [126 218]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 227\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time_diff \u001b[38;5;241m<\u001b[39m DELTA_T:\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m client\u001b[38;5;241m.\u001b[39msleep(DELTA_T \u001b[38;5;241m-\u001b[39m time_diff)\n\u001b[1;32m--> 227\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m main()\n",
      "Cell \u001b[1;32mIn[60], line 133\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    131\u001b[0m bird_image \u001b[38;5;241m=\u001b[39m project_image(image, old_corners)\n\u001b[0;32m    132\u001b[0m bird_image \u001b[38;5;241m=\u001b[39m show_path(bird_image\u001b[38;5;241m.\u001b[39mcopy(), path, search_start)\n\u001b[1;32m--> 133\u001b[0m is_cam_obstructed \u001b[38;5;241m=\u001b[39m \u001b[43mis_cam_obstructed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# FILTERING KALMAN\u001b[39;00m\n\u001b[0;32m    135\u001b[0m is_thymio_found, thymio_position_vision, theta_vision \u001b[38;5;241m=\u001b[39m get_thymio_pose(bird_image)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'bool' object is not callable"
     ]
    }
   ],
   "source": [
    "# q_x = q_y = 2.74e-1\n",
    "# q_theta = 1.24e-1\n",
    "# q_vx = q_vy = 1.52\n",
    "\n",
    "# r_x =  0.11e-1\n",
    "# r_y = 0.21e-1\n",
    "# r_theta = 3.59e-5\n",
    "# r_vx = r_vy = 2.52\n",
    "q_x = q_y = 0.00017\n",
    "q_theta = 0.00098\n",
    "q_vx = q_vy = 0.0178\n",
    "\n",
    "r_x = r_y = 5.396e-05\n",
    "r_theta = 9.008e-05\n",
    "r_vx = r_vy = 1.213\n",
    "\n",
    "#vision coeff\n",
    "r_x_vision = r_y_vision = 5.396e-05\n",
    "r_theta_vision = 9.008e-05\n",
    "r_vx = r_vy = 1.213\n",
    "\n",
    "C_not_obstructed = np.eye(5)\n",
    "\n",
    "C_obstructed = np.array([[0,0,0,0,0],\n",
    "                         [0,0,0,0,0],\n",
    "                         [0,0,0,0,0],\n",
    "                         [0,0,0,1,0],\n",
    "                         [0,0,0,0,1],\n",
    "                         ])\n",
    "\n",
    "R_obstructed = np.array([[np.inf,0,0,0,0],\n",
    "                         [0,np.inf,0,0,0],\n",
    "                         [0,0,np.inf,0,0],\n",
    "                         [0,0,0,1.21,0],\n",
    "                        [0,0,0,0,1.21]])\n",
    "\n",
    "\n",
    "R_not_obstructed = np.array([\n",
    "                        [r_x,0,0,0,0],\n",
    "                        [0,r_y,0,0,0],\n",
    "                        [0,0,r_theta,0,0],\n",
    "                        [0,0,0, r_vx,0],\n",
    "                        [0,0,0,0, r_vy]\n",
    "                        ])\n",
    "\n",
    "Q = np.array([\n",
    "            [q_x,0,0,0,0],\n",
    "            [0,q_y,0,0,0],\n",
    "            [0,0,q_theta,0,0],\n",
    "            [0,0,0,q_vx,0],\n",
    "            [0,0,0,0,q_vy]\n",
    "            ])\n",
    "\n",
    "async def main():\n",
    "    global x_odom, y_odom, theta_odom, is_cam_obstructed, thymio_position_vision,is_thymio_found, path, search_goal, search_start, map, u_state_prev,  sigma_post_odom, button_forward, is_obstacle\n",
    "\n",
    "    is_obstacle = False\n",
    "    # VISION\n",
    "    # open the default camera\n",
    "    cam = cv2.VideoCapture(1)\n",
    "    if not cam.isOpened():\n",
    "            print(\"Error: Could not open camera.\")\n",
    "\n",
    "    # convert camera resolution from 1920x1080 to 1024x768\n",
    "    cam.set(cv2.CAP_PROP_FRAME_WIDTH, 1024)\n",
    "    cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 768)\n",
    "\n",
    "    map, search_goal, search_start, theta_vision_init, old_corners = initialise_setup(cam) # in (x, y, theta_rad)_v\n",
    "\n",
    "    # INIT POUR KALMAN\n",
    "    x_vision, y_vision = thymio_transform_pose(search_start, search_start) # in (x, y, theta_rad)_t\n",
    "    \n",
    "    mu_post_vision = np.array([[x_vision], [y_vision], [theta_vision_init], [0], [0]])\n",
    "    mu_post_odom = np.array([[0], [0], [theta_vision_init], [0], [0]])\n",
    "    \n",
    "    u_state_prev = np.transpose(np.array([0,0]))\n",
    "    sigma_post_odom = np.array([\n",
    "                                [0,0,0,0,0],\n",
    "                                [0,0,0,0,0],\n",
    "                                [0,0,0,0,0],\n",
    "                                [0,0,0,0,0],\n",
    "                                [0,0,0,0,0]\n",
    "                                ])\n",
    "    \n",
    "    sigma_post_vision = np.array([\n",
    "                                [0,0,0,0,0],\n",
    "                                [0,0,0,0,0],\n",
    "                                [0,0,0,0,0],\n",
    "                                [0,0,0,0,0],\n",
    "                                [0,0,0,0,0]\n",
    "                                ])\n",
    "\n",
    "    map_image = np.float32(map.copy())\n",
    "    map_image[map == -1] = 255\n",
    "    cv2.imwrite(\"blue filter.jpg\", map_image)\n",
    "\n",
    "    # PATH PLANNING\n",
    "    # print(search_goal, search_start)\n",
    "    # print('hahah')\n",
    "    # print(map)\n",
    "    path = path_planning_a_star(map, search_start, search_goal)\n",
    "    path = path_finalizing(path, search_start, SCALING_FACTOR) # in (x, y, theta_rad)_t\n",
    "    path = [(float(x), float(y), float(theta)) for x, y, theta in path]\n",
    "    path_print = [(float(x), float(y), float(np.rad2deg(theta))) for x, y, theta in path]\n",
    "    print('path: ', path_print)\n",
    "\n",
    "    x_odom = y_odom = 0\n",
    "    theta_odom = theta_vision_init\n",
    "    print('theta vision init: ', theta_odom)\n",
    "\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "        ret, image = cam.read()\n",
    "        await node.wait_for_variables({\n",
    "            \"motor.left.speed\",\n",
    "            \"motor.right.speed\",\n",
    "            \"button.center\",\n",
    "            \"button.forward\",\n",
    "            \"prox.horizontal\",\n",
    "            \"acc\"\n",
    "        })\n",
    "\n",
    "        # variables\n",
    "        motor_left = node[\"motor.left.speed\"]\n",
    "        motor_right = node[\"motor.right.speed\"]\n",
    "        button_center = node[\"button.center\"]\n",
    "        button_forward = node[\"button.forward\"]\n",
    "        prox_horizontal = node[\"prox.horizontal\"] #tableau contenant les 7 capteurs de proximité\n",
    "        acceleration = node[\"acc\"]\n",
    "\n",
    "        bird_image = project_image(image, old_corners)\n",
    "        bird_image = show_path(bird_image.copy(), path, search_start)\n",
    "        is_cam_obstructed = is_cam_obstructed(image)\n",
    "        # FILTERING KALMAN\n",
    "        is_thymio_found, thymio_position_vision, theta_vision = get_thymio_pose(bird_image)\n",
    "        theta_vision = normalize_angle(theta_vision)\n",
    "        x_vision, y_vision = thymio_transform_pose(thymio_position_vision, search_start) # in (x, y, theta_rad)_t\n",
    "\n",
    "        if not is_cam_obstructed:\n",
    "            # print('using vision')\n",
    "            mu_post_vision, sigma_post_vision = EKF(x_vision, y_vision, theta_vision, 0, 0, mu_post_vision, u_state_prev, sigma_post_vision, R_not_obstructed, C_not_obstructed, False)\n",
    "            pose = (mu_post_vision[0, 0], mu_post_vision[1, 0], normalize_angle(mu_post_vision[2, 0]))\n",
    "\n",
    "        else:\n",
    "            # print('using odom')\n",
    "            x_odom, y_odom, theta_odom, _, _= odometrie(x_odom,y_odom,theta_odom, motor_right, motor_left)\n",
    "            theta_odom = normalize_angle(theta_odom)\n",
    "            mu_post_odom, sigma_post_odom = EKF(x_odom, y_odom, theta_odom, motor_right, motor_left, mu_post_odom, u_state_prev, sigma_post_odom, R_obstructed, C_obstructed, True)\n",
    "            pose = (float(mu_post_odom[0, 0]), float(mu_post_odom[1, 0]), normalize_angle(float(mu_post_odom[2, 0])))\n",
    "            # pose = (x_odom, y_odom, theta_odom)\n",
    "\n",
    "        # x_odom, y_odom, theta_odom, _, _= odometrie(x_odom,y_odom,theta_odom, motor_right, motor_left)\n",
    "        bird_image = show_kalman(bird_image, pose, sigma, search_start)\n",
    "        cv2.imshow(\"bird image\", bird_image)\n",
    "        cv2.imwrite(\"path_image.png\", bird_image)\n",
    "\n",
    "        print('pose_x_vi: ', x_vision, 'pose_y_vi: ', y_vision, 'angle vision: ', np.rad2deg(theta_vision))\n",
    "        print('pose_x_odom: ', x_odom, 'pose_y_odom: ', y_odom, 'angle odom: ', np.rad2deg(theta_odom))\n",
    "        print('x filtered: ', pose[0], 'y filtered: ', pose[1], 'angle filtered: ', np.rad2deg(pose[2]))\n",
    "        # print('cam obstructed? ', is_cam_obstructed)\n",
    "\n",
    "        # LOCAL AVOIDANCE\n",
    "        motor_speed, is_obstacle = local_avoidance(prox_horizontal)\n",
    "        is_kidnapped = kidnapping(acceleration, prox_horizontal)\n",
    "\n",
    "        if is_kidnapped:\n",
    "             await node.set_variables(motors(0, 0))\n",
    "        elif is_obstacle:\n",
    "            await node.set_variables(motors(motor_speed[0], motor_speed[1]))\n",
    "        else:\n",
    "            u_state_prev[0],u_state_prev[1] = await motion_control(pose, path)\n",
    "            \n",
    "        \n",
    "    \n",
    "        \n",
    "\n",
    "        # if is_obstacle:\n",
    "        #     await node.set_variables(motors(motor_speed[0], motor_speed[1]))\n",
    "\n",
    "        # else:\n",
    "\n",
    "        #     # KIDNAPPING\n",
    "        #     is_kidnapped = kidnapping(acceleration, prox_horizontal)\n",
    "            \n",
    "        #     if is_kidnapped:\n",
    "        #         await node.set_variables(motors(0, 0))\n",
    "            \n",
    "        #     u_state_prev[0],u_state_prev[1] = await motion_control(pose, path)\n",
    "\n",
    "\n",
    "        # MOTION CONTROL\n",
    "        # u_state_prev[0],u_state_prev[1] = await motion_control(pose, path)\n",
    "        # print('u_state_prev: ', u_state_prev)\n",
    "\n",
    "        # PLOTTING\n",
    "        # x_kalman.append(x_filtered)\n",
    "        # y_kalman.append(y_filtered)\n",
    "        # line.set_data(x_kalman,y_kalman)\n",
    "\n",
    "        ## erase previous ellipses\n",
    "        # for patch in reversed(ax.patches):\n",
    "        #     patch.remove()\n",
    "\n",
    "        # add ellipses\n",
    "        # plot_gaussian(ax, [x_odom, y_odom], Sigma[:2, :2], color='red') #on prend uniquement la partie de la matrice de variance correspondante à x et y donc une sub matrice 2x2\n",
    "        # fig.canvas.draw()\n",
    "\n",
    "        # fig.canvas.flush_events()\n",
    "\n",
    "        # THYMIO DIRECT CONTROL\n",
    "        if button_forward == 1:\n",
    "            await node.set_variables(motors(100, 100))\n",
    "\n",
    "        if button_center == 1:\n",
    "            await node.set_variables(motors(0, 0))\n",
    "            x_odom = y_odom = theta_odom = 0\n",
    "            break\n",
    "\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    time_diff = time.time() - start_time\n",
    "\n",
    "    if time_diff < DELTA_T:\n",
    "        await client.sleep(DELTA_T - time_diff)\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = path_planning_a_star(map, search_start, search_goal) \n",
    "#path_show = thymio_transform_path(path, search_start)\n",
    "\n",
    "# path = path_finalizing(path, search_start, SCALING_FACTOR) # in (x, y, theta_rad)_t\n",
    "# path = [(float(x), float(y), float(theta)) for x, y, theta in path]\n",
    "#display_map(map, path, search_start, search_goal)\n",
    "#print(path_show)\n",
    "print(search_start, search_goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = path_planning_a_star(map, search_start, search_goal) \n",
    "path_show = thymio_transform_path(path, search_start)\n",
    "\n",
    "# path = path_finalizing(path, search_start, SCALING_FACTOR) # in (x, y, theta_rad)_t\n",
    "# path = [(float(x), float(y), float(theta)) for x, y, theta in path]\n",
    "display_map(map, path, search_start, search_goal)\n",
    "print(path_show)\n",
    "print(search_start, search_goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
