{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Node d03d4c82-c7d9-461b-9284-191eb97b1e15"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tdmclient import ClientAsync\n",
    "import cv2\n",
    "from scipy.spatial import distance as dist \n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import math\n",
    "%matplotlib qt\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import numpy as np\n",
    "client = ClientAsync()\n",
    "node = await client.wait_for_node()\n",
    "\n",
    "await node.lock()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FILTERING\n",
    "THYMIO_MMS = 0.12 # Thymio's unit to mm/s\n",
    "D_BASELINE = 100 # mm\n",
    "DELTA_T = 0.5 # s\n",
    "SIZE_PLOT = 110\n",
    "KIDNAP_THRESHOLD = 5\n",
    "\n",
    "# MOTION CONTROL\n",
    "SUCCESS_THRESHOLD = 40 \n",
    "VELOCITY_THRESHOLD = 75 \n",
    "\n",
    "# VISION\n",
    "SCALING_FACTOR = 20/3\n",
    "\n",
    "# color filters\n",
    "HSV_RED_MIN = np.array([165, 30, 30])\n",
    "HSV_RED_MAX = np.array([180, 255, 255])\n",
    "\n",
    "HSV_ORANGE_MIN = np.array([0, 30, 30])\n",
    "HSV_ORANGE_MAX = np.array([15, 255, 255])\n",
    "\n",
    "HSV_GREEN_MIN = np.array([65, 40, 40])\n",
    "HSV_GREEN_MAX = np.array([85, 255, 255])\n",
    "\n",
    "HSV_BLUE_MIN = np.array([85, 100, 100])\n",
    "HSV_BLUE_MAX = np.array([110, 255, 255])\n",
    "\n",
    "TOLERANCE_HSV = np.array([8, 100, 100])\n",
    "\n",
    "# change those values with the camera \n",
    "RED_BGR = np.array([115, 95, 194], dtype = np.uint8)\n",
    "BLUE_BGR = np.array([134, 73, 12], dtype= np.uint8)\n",
    "GREEN_BGR = np.array([29, 72, 56], dtype = np.uint8)\n",
    "ORANGE_BGR = np.array([134, 73, 12], dtype = np.uint8)\n",
    "\n",
    "# camera and map parameters\n",
    "CAMERA_WIDTH = 1024\n",
    "CAMERA_HEIGHT = 768\n",
    "BIRD_WIDTH = 660\n",
    "BIRD_HEIGHT = 492\n",
    "MAP_WIDTH = 330\n",
    "MAP_HEIGHT = 246\n",
    "REAL_WIDTH = 1100\n",
    "REAL_HEIGHT = 820\n",
    "CAMERA_CORNERS = [[0, 0], [CAMERA_WIDTH, 0], [CAMERA_WIDTH, CAMERA_HEIGHT], [0, CAMERA_HEIGHT]]\n",
    "BIRD_CORNERS = [[0, 0], [BIRD_WIDTH, 0], [BIRD_WIDTH, BIRD_HEIGHT], [0, BIRD_HEIGHT]]\n",
    "MAP_CORNERS = np.array([[0, 0], [MAP_WIDTH, 0], [MAP_WIDTH, MAP_HEIGHT], [0, MAP_HEIGHT]], dtype=np.float32)\n",
    "\n",
    "# matching thresholds\n",
    "RES_THRESHOLD_BLACK = 0.84\n",
    "RES_THRESHOLD_RED = 0.4\n",
    "RES_THRESHOLD_GREEN = 0.3\n",
    "\n",
    "# binary thresholds\n",
    "BINARY_THRESHOLD_BLACK = 27\n",
    "BINARY_THRESHOLD_RED = 27\n",
    "BINARY_THRESHOLD_GREEN = 50\n",
    "BINARY_THRESHOLD_BLUE = 23\n",
    "\n",
    "OVERLAP_THRESHOLD = 0\n",
    "THYMIO_WIDTH = 29\n",
    "NOISE_WIDTH = 9\n",
    "TEMP_CENTER_Y = 53\n",
    "TEMP_CENTER_X = 69\n",
    "\n",
    "OBSTACLE_MAP_VALUE = -1\n",
    "BACKGROUND_MAP_VALUE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#templates\n",
    "template_cross = cv2.imread('/Users/tjga9/Documents/Tomas/EPFL/MA1/Basic of Mobile Robotics/Control your Thymio in Python/Control your Thymio in Python/template_cross_dll.jpg')\n",
    "\n",
    "method = eval('cv2.TM_CCORR_NORMED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_plot():\n",
    "    fig,ax = plt.subplots()\n",
    "    line, = ax.plot([], [], '--', label=\"Position with odometry\", color =\"black\")\n",
    "    ax.set_xlim(-SIZE_PLOT, SIZE_PLOT+100)\n",
    "    ax.set_ylim(-SIZE_PLOT, SIZE_PLOT)\n",
    "    ax.set_title(\"Real time Kalmann plot\")\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.legend()\n",
    "    ax.minorticks_on()\n",
    "    ax.grid(which='major', color=\"0.75\", linestyle='-')\n",
    "    #ax.grid(which='minor', color=\"0.75\", linestyle='--')\n",
    "    plt.rcParams.update({\n",
    "        \"text.usetex\": False,\n",
    "        \"font.family\": \"sans-serif\"\n",
    "    })\n",
    "\n",
    "    return fig, ax, line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_map(map_grid, path, start, goal):\n",
    "    cmap = ListedColormap(['white', 'black', 'blue', 'green', 'red', 'grey'])\n",
    "    map_display = np.zeros_like(map_grid, dtype=object)\n",
    "\n",
    "    # Assign colors based on the map grid values\n",
    "    map_display[map_grid == -1] = 'black'  # Obstacles\n",
    "    map_display[map_grid == 0] = 'white'   # Free space\n",
    "\n",
    "    # for position in explored:\n",
    "    #     if map_display[tuple(position)] == 'white':\n",
    "    #         map_display[tuple(position)] = 'grey'  # Explored cells\n",
    "\n",
    "    # Visualize the path\n",
    "    for position in path:\n",
    "        if map_display[position[0], position[1]] in ['white', 'grey']:\n",
    "            map_display[position[0], position[1]] = 'blue'  # Path\n",
    "\n",
    "    # map_display[5, 3] = 'yellow' # Weighted cell\n",
    "    map_display[start[0], start[1]] = 'green'  # Start\n",
    "    map_display[goal[0], goal[1]] = 'red'      # Goal\n",
    "\n",
    "    # Convert color names to numbers for plotting\n",
    "    color_mapping = {'white': 0, 'black': 1, 'blue': 2, 'green': 3, 'red': 4, 'grey': 5}\n",
    "    map_numeric_display = np.vectorize(color_mapping.get)(map_display)\n",
    "    fig, ax = plt.subplots(figsize=(6, 7))\n",
    "    ax.imshow(map_numeric_display, cmap=cmap)\n",
    "    ax.set_xticks(np.arange(-0.5, map_grid.shape[1], 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-0.5, map_grid.shape[0], 1), minor=True)\n",
    "    ax.grid(which='minor', color='gray', linestyle='-', linewidth=0.5)\n",
    "    ax.tick_params(which='both', bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thymio_transform_pose(pose, start):\n",
    "    \"\"\"\n",
    "    Transform the position from vision reference (y-axis right-sided, x-axis downward) to\n",
    "    new reference with origin at the start position (y-axis upward, x-axis right-sided).\n",
    "    \n",
    "    Parameters: \n",
    "    pose (tuple): The input position in vision reference. \n",
    "    start (tuple): The input start position.\n",
    "    \n",
    "    Return:\n",
    "    list: The ouput path as a list of tuples (sub-goals) in the new reference at the start position.\n",
    "    \"\"\"\n",
    "    \n",
    "    start_x, start_y = start\n",
    "    \n",
    "    # transform the reference\n",
    "    new_x = (pose[1] - start_y)\n",
    "    new_y = -(pose[0] - start_x)\n",
    "    \n",
    "    return new_x, new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_angle(angle):\n",
    "    \"\"\"\n",
    "    Normalize the given angle to range [-π, π].\n",
    "    \n",
    "    Parameters:\n",
    "    angle (float): The input angle in radian.\n",
    "    \n",
    "    Returns:\n",
    "    float: The output normalized angle to [-π, π] in radian.\n",
    "    \"\"\"\n",
    "    \n",
    "    normalized_angle = (angle + np.pi) % (2 * np.pi) - np.pi\n",
    "    \n",
    "    return normalized_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_angle_full(angle_radians):\n",
    "    # Normalization between -2pi and 2pi\n",
    "    two_pi = 2*np.pi\n",
    "    if angle_radians >= two_pi:\n",
    "        angle_radians -= two_pi\n",
    "    elif angle_radians < -two_pi:\n",
    "        angle_radians += two_pi\n",
    "    return angle_radians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(np.rad2deg(normalize_angle(np.deg2rad(43.55))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motors(left, right):\n",
    "    return {\n",
    "        \"motor.left.target\": [left],\n",
    "        \"motor.right.target\": [right],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vision Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_corners = CAMERA_CORNERS #variable that will be updated each time\n",
    "is_cam_obstructed = False\n",
    "map = np.zeros((BIRD_HEIGHT, BIRD_WIDTH))\n",
    "bird_image = np.zeros((BIRD_HEIGHT, BIRD_WIDTH))\n",
    "hsv_img = np.zeros((BIRD_HEIGHT, BIRD_WIDTH, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_pass_hsv(bgr_color):\n",
    "\t\"\"\"given a color in bgr colorspace, returns the min and max values for the bandpass filter\"\"\"\n",
    "\thsv_color = cv2.cvtColor(bgr_color.reshape(1, 1, 3), cv2.COLOR_BGR2HSV)[0][0]\n",
    "\thsv_min = hsv_color - TOLERANCE_HSV\n",
    "\thsv_max = hsv_color + TOLERANCE_HSV\n",
    "\n",
    "\treturn hsv_min, hsv_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_hsv_to_binary_old(hsv_img, hsv_min, hsv_max, binary_threshold):\n",
    "\t\"\"\"transform a HSV image to a binary image with threshold of the desired color\n",
    "\t| hsv_img : image in the hsv colorspace\n",
    "\t| hsv_min, hsv_max : min and max of color filter\n",
    "\t| binary_threshold : threshold under which the pixel is 0 and over which the pixel is 255\"\"\"\n",
    "\t#keep only the desired color in hsv\n",
    "\tmask = cv2.inRange(hsv_img, hsv_min, hsv_max)\n",
    "\toutput = cv2.bitwise_and(hsv_img,hsv_img, mask= mask)\n",
    "\n",
    "\tgrayscale = output[:, :, 2]\n",
    "\t#convert to binary\n",
    "\tthreshold = binary_threshold\n",
    "\tret, bw = cv2.threshold(grayscale, threshold, 255, cv2.THRESH_BINARY)\n",
    "\treturn bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_to_hsv(image):\n",
    "\t\"\"\"Filters the image from BGR colorspace to HSV colorspace\"\"\"\n",
    "\tfiltered_img = cv2.GaussianBlur(image,(5,5),1)\n",
    "    \n",
    "    # Convert BGR to HSV\n",
    "\thsv_img = cv2.cvtColor(filtered_img, cv2.COLOR_BGR2HSV)\n",
    "\treturn hsv_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_hsv_to_binary(hsv_img, bgr_color, binary_threshold):\n",
    "\t\"\"\"filters the color of an hsv image to a binary image\n",
    "\t| hsv img : image in the hsv colorspace\n",
    "\t| bgr_color : color to filter in the bgr colorspace\n",
    "\t| binary threshold : value btw 0 and 255 for binary filter\"\"\"\n",
    "\thsv_min, hsv_max = band_pass_hsv(bgr_color)\n",
    "\tmask = cv2.inRange(hsv_img, hsv_min, hsv_max)\n",
    "\toutput = cv2.bitwise_and(hsv_img,hsv_img, mask= mask)\n",
    "\tgrayscale = output[:, :, 2]\n",
    "\t#convert to binary\n",
    "\tthreshold = binary_threshold\n",
    "\tret, bw = cv2.threshold(grayscale, threshold, 255, cv2.THRESH_BINARY)\n",
    "\treturn bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_back_coord(pose, start):\n",
    "    #pose is in (x, y) of thymio ref, start is (y, x) in matrix ref, converts to (x,y) to feed to opencv\n",
    "    start_y, start_x = start\n",
    "    new_x = pose[0] + start_x\n",
    "    new_y = -pose[1] + start_y\n",
    "\n",
    "    return np.array([new_x, new_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_path(image, path, start):\n",
    "    #normalize coordinates ? we project onto an image twice bigger than our coord -> need to double the coord\n",
    "    previous = transform_back_coord(path[0], start)*2\n",
    "    print(\"previous\", previous)\n",
    "    for i in range(1, len(path)):\n",
    "\n",
    "        current = transform_back_coord(path[i], start)*2\n",
    "        print(\"current\", current)\n",
    "        print(\"previous\", previous)\n",
    "        print(\"current\", current)\n",
    "        cv2.line(image, previous, current, (0, 0, 255), 3)\n",
    "        previous = current\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_grayscale(img):\n",
    "\t\"given image in bgr colorspace, convert it to grayscale then convert it to binary\"\n",
    "\t#convert to grayscale both image and template\n",
    "\timg_grayscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\t#convert to binary both image and template\n",
    "\tthreshold = BINARY_THRESHOLD_BLACK\n",
    "\tret, image_binary = cv2.threshold(img_grayscale, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\treturn image_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "\t\"\"\"Makes sure to only have one set of coordinate per cross to find the corners of the map\"\"\"\n",
    "\t# if there are no boxes, return an empty list\n",
    "\tif len(boxes) == 0:\n",
    "\t\treturn []\n",
    "\t# if the bounding boxes integers, convert them to floats --\n",
    "\t# this is important since we'll be doing a bunch of divisions\n",
    "\tif boxes.dtype.kind == \"i\":\n",
    "\t\tboxes = boxes.astype(\"float\")\n",
    "\t# initialize the list of picked indexes\t\n",
    "\tpick = []\n",
    "\t# grab the coordinates of the bounding boxes\n",
    "\tx1 = boxes[:,0]\n",
    "\ty1 = boxes[:,1]\n",
    "\tx2 = boxes[:,2]\n",
    "\ty2 = boxes[:,3]\n",
    "\t# compute the area of the bounding boxes and sort the bounding\n",
    "\t# boxes by the bottom-right y-coordinate of the bounding box\n",
    "\tarea = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "\tidxs = np.argsort(y2)\n",
    "\t# keep looping while some indexes still remain in the indexes\n",
    "\t# list\n",
    "\twhile len(idxs) > 0:\n",
    "\t\t# grab the last index in the indexes list and add the\n",
    "\t\t# index value to the list of picked indexes\n",
    "\t\tlast = len(idxs) - 1\n",
    "\t\ti = idxs[last]\n",
    "\t\tpick.append(i)\n",
    "\t\t# find the largest (x, y) coordinates for the start of\n",
    "\t\t# the bounding box and the smallest (x, y) coordinates\n",
    "\t\t# for the end of the bounding box\n",
    "\t\txx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "\t\tyy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "\t\txx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "\t\tyy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\t\t# compute the width and height of the bounding box\n",
    "\t\tw = np.maximum(0, xx2 - xx1 + 1)\n",
    "\t\th = np.maximum(0, yy2 - yy1 + 1)\n",
    "\t\t# compute the ratio of overlap\n",
    "\t\toverlap = (w * h) / area[idxs[:last]]\n",
    "\t\t# delete all indexes from the index list that have\n",
    "\t\tidxs = np.delete(idxs, np.concatenate(([last],\n",
    "\t\t\tnp.where(overlap > overlapThresh)[0])))\n",
    "\t# return only the bounding boxes that were picked using the\n",
    "\t# integer data type\n",
    "\treturn boxes[pick].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "\t\"\"\"Orders points of rectangle so that they are in the order : top_left, top_right, bottom_right, bottom_left \"\"\"\n",
    "\t# sort the points based on their x-coordinates\n",
    "\txSorted = pts[np.argsort(pts[:, 0]), :]\n",
    "\t# grab the left-most and right-most points from the sorted\n",
    "\t# x-roodinate points\n",
    "\tleftMost = xSorted[:2, :]\n",
    "\trightMost = xSorted[2:, :]\n",
    "\t# now, sort the left-most coordinates according to their\n",
    "\t# y-coordinates so we can grab the top-left and bottom-left\n",
    "\t# points, respectively\n",
    "\tleftMost = leftMost[np.argsort(leftMost[:, 1]), :]\n",
    "\t(tl, bl) = leftMost\n",
    "\t# now that we have the top-left coordinate, use it as an\n",
    "\t# anchor to calculate the Euclidean distance between the\n",
    "\t# top-left and right-most points; by the Pythagorean\n",
    "\t# theorem, the point with the largest distance will be\n",
    "\t# our bottom-right point\n",
    "\tD = dist.cdist(tl[np.newaxis], rightMost, \"euclidean\")[0]\n",
    "\t(br, tr) = rightMost[np.argsort(D)[::-1], :]\n",
    "\t# return the coordinates in top-left, top-right,\n",
    "\t# bottom-right, and bottom-left order\n",
    "\treturn np.array([tl, tr, br, bl], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_4_corners(img, template, method):\n",
    "\t\"\"\"Finds the coordiantes of the corners of the map; \t\n",
    "\targuments :\t\n",
    "\t| img : image in the bgr color space;\t\n",
    "\t| template : image that has been filtered and is in the binary color space;\t\n",
    "\t| method : cross-correlation method for template matching\n",
    "\t\"\"\"\n",
    "\tis_found = False\n",
    "\t\n",
    "\t#filter the image\n",
    "\tfiltered_img = cv2.GaussianBlur(img,(5,5), 1)\n",
    "\t\n",
    "\t#convert image and template to binary\n",
    "\timage_binary = filter_grayscale(filtered_img)\n",
    "\ttemplate_binary = filter_grayscale(template)\n",
    "\t\n",
    "\t#cv2.imshow(\"binary of black\", image_binary)\n",
    "\t#get template dimensions\n",
    "\tc, w, h  = template.shape[::-1]\n",
    "\t#print(template.shape[::-1])\n",
    "\t\n",
    "\t#match template to image\n",
    "\tres = cv2.matchTemplate(image_binary,template_binary,method)\n",
    "\t(yCoords, xCoords) = np.where(res >= RES_THRESHOLD_BLACK)\n",
    "\n",
    "\n",
    "\t# initialize our list of rectangles\n",
    "\trects = []\n",
    "\t# loop over the starting (x, y)-coordinates again\n",
    "\tfor (x, y) in zip(xCoords, yCoords):\n",
    "\t\t# update our list of rectangles\n",
    "\t\trects.append((x, y, x + w, y + h))\n",
    "\t\n",
    "\t# apply non-maxima suppression to the rectangles\n",
    "\tpick = non_max_suppression_fast(np.array(rects), OVERLAP_THRESHOLD)\n",
    "\t#print(\"[INFO] {} matched locations after NMS\".format(len(pick)))\n",
    "\t\n",
    "\t#create a list of centers of the rectangles\n",
    "\tcross_points = []\n",
    "\tfor (startX, startY, endX, endY) in pick:\n",
    "\t    # draw the bounding box on the image\n",
    "\t\tcv2.rectangle(image_binary, (startX, startY), (endX, endY), (0, 0, 255), 3)\n",
    "\t\tcross_points.append([int((startX+endX)/2), int((startY+ endY)/2)]) \n",
    "\n",
    "\t#cv2.imshow(\"binary of black\", image_binary)\n",
    "\t#cv2.imshow(\"template\", template_binary)\n",
    "\n",
    "\tif (len(pick) == 4) :\n",
    "\t\tis_found = True\n",
    "\t\n",
    "\tcross_points = np.array(cross_points)\n",
    "\tcv2.imwrite(\"template_cross_binary.png\", image_binary)\n",
    "\t\n",
    "\treturn is_found, cross_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_image(image, template, method, old_corners):\n",
    "\t\"\"\"Transforms the camera image to a map bird's eye view with only the map\"\"\"\n",
    "\tis_found, cross_points = find_4_corners(image, template, method)\n",
    "\t\n",
    "\tif is_found:\n",
    "\t\tordered_crosses = order_points(cross_points)\n",
    "\t\t#store corners positions in case we have a frame where we don't see them anymore\n",
    "\t\told_corners = ordered_crosses\n",
    "\telse : \n",
    "\t\t#will become the last found corners, \n",
    "\t\tordered_crosses = old_corners\n",
    "\n",
    "\tordered_crosses = np.float32(ordered_crosses)\n",
    "\tbird_corners = np.float32(BIRD_CORNERS)\n",
    "\n",
    "\tmatrix = cv2.getPerspectiveTransform(ordered_crosses, bird_corners)\n",
    "\tbird_image = cv2.warpPerspective(image, matrix, (BIRD_WIDTH, BIRD_HEIGHT))\n",
    "\n",
    "\treturn is_found, bird_image, old_corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_obstacles(hsv_image):\n",
    "\t\"\"\"Finds the obstacles (orange parts) on the map and put them on the map\"\"\"\n",
    "\t#filter the orange color\n",
    "\thsv_min, hsv_max = band_pass_hsv(BLUE_BGR)\n",
    "\tmask = cv2.inRange(hsv_image, HSV_BLUE_MIN, HSV_BLUE_MAX)\n",
    "\toutput = cv2.bitwise_and(hsv_image,hsv_image, mask= mask)\n",
    "\t#cv2.imshow(\"output of blue filter\", output)\n",
    "\t#convert map to binary (0 = no obstacle, 1 = obstacle)\n",
    "\toutput_gray = output[:, :, 2]\n",
    "\t\n",
    "\tthreshold = BINARY_THRESHOLD_BLUE\n",
    "\tret, map = cv2.threshold(output_gray, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\t#map[map==255] = OBSTACLE_MAP_VALUE\n",
    "\treturn map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilate_obstacles(map, width):\n",
    "\t\"\"\"Dilates the obstacles to approximate the size of the thymio to one pixel\n",
    "\tmap : [array] of 0 (background) and 1 (obstacles)\n",
    "\twidth : [int] half the width of the thymio in pixels\"\"\"\n",
    "\n",
    "\tdilation_shape = cv2.MORPH_RECT\n",
    "\tkernel = cv2.getStructuringElement(dilation_shape, (2*width + 1, 2*width + 1), (width, width))\n",
    "\tnoise_kernel = cv2.getStructuringElement(dilation_shape, (2*NOISE_WIDTH+1, 2*NOISE_WIDTH+1), (NOISE_WIDTH, NOISE_WIDTH))\n",
    "\teroded_image = cv2.erode(map, noise_kernel, iterations = 1)\n",
    "\teroded_image = cv2.dilate(eroded_image, noise_kernel, iterations = 1) \n",
    "\tdilated_img = cv2.dilate(eroded_image, kernel, iterations = 1)\n",
    "\n",
    "\treturn dilated_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_map_borders(map, width):\n",
    "\t\"\"\"put the borders of the map as obstacles\"\"\"\n",
    "\tmap[0:width, :MAP_WIDTH] = 255\n",
    "\tmap[:MAP_HEIGHT, MAP_WIDTH-width:MAP_WIDTH] = 255\n",
    "\tmap[MAP_HEIGHT-width: MAP_HEIGHT, :MAP_WIDTH] = 255\n",
    "\tmap[:MAP_HEIGHT, 0:width] = 255\n",
    "\treturn map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_map(hsv_image):\n",
    "\t\"\"\"take the bird's eye image and convert it to a map, without the goal coordinates\"\"\"\n",
    "\tbird_corners = np.array(BIRD_CORNERS, dtype = np.float32)\n",
    "\tmap_corners = np.array(MAP_CORNERS, dtype = np.float32)\n",
    "\tmatrix = cv2.getPerspectiveTransform(bird_corners, map_corners)\n",
    "\tbird_image = cv2.warpPerspective(hsv_image, matrix, (MAP_WIDTH, MAP_HEIGHT))\n",
    "\t\n",
    "\tobstacles = create_obstacles(bird_image)\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\tdilated_map = dilate_obstacles(obstacles, THYMIO_WIDTH)\n",
    "\tcv2.imwrite(\"map_inside_createMap.jpg\", dilated_map)\n",
    "\tmap = create_map_borders(dilated_map, THYMIO_WIDTH)\n",
    "\t#map[map == 255] = OBSTACLE_MAP_VALUE\n",
    "\treturn map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_goal_coord(hsv_img, template, method):\n",
    "\t\"\"\"Finds the position of the goal in the map, returns corners of rectangle and position\n",
    "\t| hsv_img : image in the hsv colorspace\n",
    "\t| template : template in binary colorspace of the goal\n",
    "\t| method : the cross correlation method (see exercises week 3)\"\"\"\n",
    "\t#keep only the green (color of goal)\n",
    "\t#bw = filter_hsv_to_binary(hsv_img, GREEN_BGR, BINARY_THRESHOLD_GREEN)\n",
    "\t#cv2.imshow(\"hsv img\", hsv_img)\n",
    "\t#hsv_min, hsv_max = band_pass_hsv(bgr_color)\n",
    "\tmask = cv2.inRange(hsv_img, HSV_GREEN_MIN, HSV_GREEN_MAX)\n",
    "\toutput = cv2.bitwise_and(hsv_img,hsv_img, mask= mask)\n",
    "\t#cv2.imshow(\"green banddpass\", output)\n",
    "\tgrayscale = output[:, :, 2]\n",
    "\t#convert to binary\n",
    "\tthreshold = BINARY_THRESHOLD_GREEN\n",
    "\tret, bw = cv2.threshold(grayscale, threshold, 255, cv2.THRESH_BINARY)\n",
    "\t\n",
    "\ttemplate_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "\tret, template_bw = cv2.threshold(template_gray, BINARY_THRESHOLD_GREEN, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\t#cv2.imshow(\"green filter\", bw)\n",
    "\n",
    "\t#find template coordinates\n",
    "\tres = cv2.matchTemplate(bw, template_bw, method)\n",
    "\tmin_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "\t#get template dimensions\n",
    "\tc, w, h  = template.shape[::-1]\n",
    "\t#determine if we have found the coordinates or if it might be a fake\n",
    "\tif max_val >= RES_THRESHOLD_RED:\n",
    "\t\tis_found = True\n",
    "\t\ttop_left = max_loc\n",
    "\t\tbottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "\t\tposition = (top_left[0] + int(w/2), top_left[1] + int(h/2))\n",
    "\telse:\n",
    "\t\tis_found = False\n",
    "\t\ttop_left = (0, 0)\n",
    "\t\tbottom_right = (w, h)#set the thymio position to the top left corner if we haven't found it\n",
    "\t\tposition = (0, 0)\n",
    "\n",
    "\tcX, cY = position\n",
    "\tposition = (cY, cX) #invert positions to make the axis like those of a np array\n",
    "\treturn is_found, position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_goal(hsv_img):\n",
    "\t\"\"\"Finds coordinates of thymio\n",
    "\targuments :\t\n",
    "\t| bw : image in the binary color space;\t\n",
    "\t| template : image that has been filtered and is in the binary color space (1 dim);\t\n",
    "\t| method : cross-correlation method for template matching\n",
    "\t\"\"\"\n",
    "\tis_found = False\n",
    "\tmask = cv2.inRange(hsv_img, HSV_GREEN_MIN, HSV_GREEN_MAX)\n",
    "\toutput = cv2.bitwise_and(hsv_img,hsv_img, mask= mask)\n",
    "\t#cv2.imshow(\"green banddpass\", output)\n",
    "\tgrayscale = output[:, :, 2]\n",
    "\t#convert to binary\n",
    "\tthreshold = BINARY_THRESHOLD_GREEN\n",
    "\tret, bw = cv2.threshold(grayscale, threshold, 255, cv2.THRESH_BINARY)\n",
    "\t\t\n",
    "\t#cv2.imshow(\"green filter\", bw)\n",
    "\t#cv2.imwrite(\"red_filter.jpg\", bw)\n",
    "\t\n",
    "\t#find location of thymio\n",
    "\tcontours, hierarchy  = cv2.findContours(bw, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\t#print(len(contours), \"elements found\")\n",
    "\tif len(contours) != 0:\n",
    "\t\t#if contour detected, keep the biggest one (most likely the thymio)\n",
    "\t\tcontours = sorted(contours, key = cv2.contourArea, reverse = True)\n",
    "\t\tcontour = contours[0]\n",
    "\n",
    "\t\tcontour_threshold = 30 #detect if contour found is too small\n",
    "\t\tM = cv2.moments(contour)\n",
    "\t\tif (M[\"m00\"] != 0) and (cv2.contourArea(contour) >= contour_threshold) :\n",
    "\t\t\tcX = int(M[\"m10\"]/M[\"m00\"])\n",
    "\t\t\tcY = int(M[\"m01\"]/M[\"m00\"])\n",
    "\t\t\tis_found = True\n",
    "\t\t\tposition = (cY//2, cX//2)\n",
    "\t\telse :\n",
    "\t\t\t#division by zero or no contour big enough found\n",
    "\t\t\t#print(M[\"m00\"], \"contour too small\") \n",
    "\t\t\tposition = (0, 0)\n",
    "\t\t\tis_found = False\n",
    "\telse:\n",
    "\t\t#no contour found\n",
    "\t\t#print(\"no contours found\")\n",
    "\t\tposition = (0, 0)\n",
    "\t\tis_found = False\n",
    "\t\n",
    "\treturn is_found, position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_l_thymio(bw):\n",
    "\t\"\"\"Finds coordinates of thymio\n",
    "\targuments :\t\n",
    "\t| bw : image in the binary color space;\t\n",
    "\t| template : image that has been filtered and is in the binary color space (1 dim);\t\n",
    "\t| method : cross-correlation method for template matching\n",
    "\t\"\"\"\n",
    "\tis_found = False\n",
    "\n",
    "\t#find location of thymio\n",
    "\tcontours, hierarchy  = cv2.findContours(bw, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\t#print(len(contours), \"elements found\")\n",
    "\tif len(contours) >= 2:\n",
    "\t\t#if contour detected, keep the biggest one (most likely the thymio)\n",
    "\t\tcontours = sorted(contours, key = cv2.contourArea, reverse = True)\n",
    "\t\tbig_circle = contours[0]\n",
    "\t\tsmall_circle = contours[1]\n",
    "\n",
    "\t\tcontour_threshold = 10 #detect if contour found is too small\n",
    "\t\tM_big = cv2.moments(big_circle)\n",
    "\t\tM_small = cv2.moments(small_circle)\n",
    "\t\tif (M_big[\"m00\"] != 0) and (M_small[\"m00\"] != 0) and (cv2.contourArea(big_circle) >= contour_threshold) and (cv2.contourArea(small_circle) >= contour_threshold):\n",
    "\t\t\tcX_big = int(M_big[\"m10\"]/M_big[\"m00\"])\n",
    "\t\t\tcY_big = int(M_big[\"m01\"]/M_big[\"m00\"])\n",
    "\t\t\tcX_small = int(M_small[\"m10\"]/M_small[\"m00\"])\n",
    "\t\t\tcY_small = int(M_small[\"m01\"]/M_small[\"m00\"])\n",
    "\t\t\tis_found = True\n",
    "\t\t\tposition = ((cX_big + cX_small)//4, (cY_big + cY_small)//4)\n",
    "\t\t\tdelta_x = cX_big - cX_small\n",
    "\t\t\tdelta_y = cY_big - cY_small\n",
    "\t\t\tangle = -(np.arctan2(delta_y, delta_x))\n",
    "\t\telse :\n",
    "\t\t\t#division by zero or no contour big enough found\n",
    "\t\t\t#print(M[\"m00\"], \"contour too small\") \n",
    "\t\t\tposition = (0, 0)\n",
    "\t\t\tis_found = False\n",
    "\t\t\tangle = 0\n",
    "\telse:\n",
    "\t\t#no contour found\n",
    "\t\t#print(\"no contours found\")\n",
    "\t\tposition = (0, 0)\n",
    "\t\tis_found = False\n",
    "\t\tangle = 0\n",
    "\t\t\n",
    "\treturn is_found, position, angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_camera_obstructed(image):\n",
    "    img_grayscale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\t#convert to binary both image and template\n",
    "    threshold = 150\n",
    "    \n",
    "    ret, image_binary = cv2.threshold(img_grayscale, threshold, 255, cv2.THRESH_BINARY)\n",
    "    zero_points = cv2.findNonZero(image_binary)\n",
    "    \n",
    "    if (zero_points is None) or (len(zero_points) < 200):\n",
    "        is_obstructed = True\n",
    "    else:\n",
    "        is_obstructed = False\n",
    "    return is_obstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_image(image, old_corners):\n",
    "    ordered_crosses = np.float32(old_corners)\n",
    "    bird_corners = np.float32(BIRD_CORNERS)\n",
    "    matrix = cv2.getPerspectiveTransform(ordered_crosses, bird_corners)\n",
    "    bird_image = cv2.warpPerspective(image, matrix, (BIRD_WIDTH, BIRD_HEIGHT))\n",
    "\n",
    "    return bird_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thymio_pose(image, old_corners):\n",
    "\t\"\"\"returns position and angle of thymio, and a boolean that is true if thymio has been found\n",
    "\t| image : camera image in the bgr colorspace\"\"\"\n",
    "\tis_cam_obstructed = is_camera_obstructed(image)\n",
    "\t\n",
    "\tif not is_cam_obstructed:\n",
    "\t\tordered_crosses = np.float32(old_corners)\n",
    "\t\tbird_corners = np.float32(BIRD_CORNERS)\n",
    "\t\tmatrix = cv2.getPerspectiveTransform(ordered_crosses, bird_corners)\n",
    "\t\tbird_image = cv2.warpPerspective(image, matrix, (BIRD_WIDTH, BIRD_HEIGHT))\n",
    "\t\thsv_img = filter_to_hsv(bird_image)\n",
    "\t\t#keep only red and filter to binary\n",
    "\t\tbw = filter_hsv_to_binary(hsv_img, RED_BGR, BINARY_THRESHOLD_RED) #i try to have the image in hsv this time\n",
    "\t\n",
    "\t\tcv2.imwrite(\"hsv_image_fed_to_red_filter.jpg\", bw)\n",
    "\t\tcv2.imwrite(\"bird_image.jpg\", bird_image)\n",
    "\n",
    "\t\t#find position of thymio\n",
    "\t\tis_found, position, angle = find_l_thymio(bw)\n",
    "\telse:\n",
    "\t\tis_found = False\n",
    "\t\tposition = (0, 0)\n",
    "\t\tangle = 0\n",
    "\n",
    "\t\n",
    "\tposition = position[::-1]\n",
    "\t# print(\"position_thymio\", is_found, position, angle)\n",
    "\tprint('............................................')\n",
    "\t\n",
    "\treturn is_cam_obstructed, is_found, position, angle #for now, the position is a pixel location, will need to convert it later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_sure_corners_are_found(image, template, method):\n",
    "\t\"\"\"Function to calibrate the camera and make sure we can detect all the corners\"\"\"\n",
    "\tis_found, cross_points = find_4_corners(image, template, method)\n",
    "\t\n",
    "\timage_copy = image.copy()\n",
    "\tfor point in cross_points:\n",
    "\t\tcv2.circle(image_copy, tuple(point), 20, (0, 0, 255), 3)\n",
    "\treturn is_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_goal_to_map(map, goal_position): #probably won't use it\n",
    "\tmap[goal_position] = 2 #value to change for now\n",
    "\treturn map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_start_to_map(map, position): #probably won't use it\n",
    "\t#might want to add a condition to be sure thymio is not on an obstacle \n",
    "\tmap[position] = 3 #value to change for now\n",
    "\treturn map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_cam_to_calibrate():\n",
    "\twhile True:\n",
    "\t\ttime.sleep(0.1)\n",
    "\t\tif cv2.waitKey(1) == ord('s'):\n",
    "\t\t\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_path(image, path):\n",
    "\t#fastest method computing time wise, but not the most visible\n",
    "\timage[path] = np.array([0, 0, 255])\n",
    "\t#way slower, but more visible\n",
    "\t#for point in path:\n",
    "\t\t#cv2.circle(image, point[::-1], 2, (0, 0, 255), -1)\n",
    "\treturn image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_setup(cam):\n",
    "\t# Open the default camera\n",
    "\t\n",
    "\t#set it for later\n",
    "\told_corners = CAMERA_CORNERS #variable that will be updated each time\n",
    "\tmap = np.zeros((BIRD_HEIGHT, BIRD_WIDTH))\n",
    "\tbird_image = np.zeros((BIRD_HEIGHT, BIRD_WIDTH))\n",
    "\thsv_img = np.zeros((BIRD_HEIGHT, BIRD_WIDTH, 3))\n",
    "\ti = 0\n",
    "\twhile i !=30:\n",
    "\t\ti +=1\n",
    "\t\tret, image = cam.read()\n",
    "\t\t\n",
    "\t\tis_thymio_found = False\n",
    "\t\tcorners_found, bird_image, old_corners = warp_image(image, template_cross, method, old_corners)\n",
    "\t\tbird_image_copy = bird_image.copy() #picture\n",
    "\t\t\n",
    "\t\tprint(\"corners found\", corners_found)\n",
    "\t\thsv_img = filter_to_hsv(bird_image)\n",
    "\t\tmap = create_map(hsv_img)\n",
    "\t\tcv2.imwrite(\"map_inside_init.jpg\", map)\n",
    "\t\tis_goal_found, goal_position = find_goal(hsv_img)\n",
    "\t\ttry:\n",
    "\t\t\tis_cam_obstructed, is_thymio_found, thymio_position, angle = get_thymio_pose(image, old_corners)\n",
    "\t\texcept:\n",
    "\t\t\tprint(\"Crashed avoided\")\n",
    "\n",
    "\t\tcv2.imshow(\"Bird's eye view\", bird_image)\n",
    "\n",
    "\t# Release the capture and writer objects\n",
    "\t\n",
    "\tcv2.destroyAllWindows()\n",
    "\tmap = np.float32(map)\n",
    "\tmap[map == 255] = -1\n",
    "\t\n",
    "\n",
    "\treturn map, goal_position, thymio_position, angle, old_corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set it for later\n",
    "old_corners = CAMERA_CORNERS #variable that will be updated each time\n",
    "\n",
    "is_cam_setup = False\n",
    "is_cam_obstructed = False\n",
    "map = np.zeros((BIRD_HEIGHT, BIRD_WIDTH))\n",
    "bird_image = np.zeros((BIRD_HEIGHT, BIRD_WIDTH))\n",
    "hsv_img = np.zeros((BIRD_HEIGHT, BIRD_WIDTH, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path Planning Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried a few different path planning methods, like Dijkstra’s algorithm and others. While Dijkstra works fine, it’s slower because it doesn’t use any kind of heuristic to guide the search, so it ends up exploring more paths than necessary. After testing a few options, we found that A*, using an 8-connected grid, was the best choice. It allows movement in all 8 directions (including diagonals), which gives it more flexibility and helps avoid unnecessary exploration. Overall, A* was faster and more efficient than the other methods, so we decided to go with it for our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic(a, b):\n",
    "    \"\"\"\n",
    "    Calculate the heuristic cost between 2 points, which specifically the current position and the goal.\n",
    "    \n",
    "    Parameters:\n",
    "    a (tuple): The input position.\n",
    "    b (tuple): The input goal.\n",
    "    \n",
    "    Return:\n",
    "    float: The output heuristic value between the current position and the goal.\n",
    "    \"\"\"\n",
    "    \n",
    "    return abs(a[0] - b[0]) + abs(a[1] - b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_planning_a_star(map_grid, start, goal):\n",
    "    \"\"\"\n",
    "    Calculate the optimal map to travel from the start position to the goal position using A* algorithm with Euclidean distance (8-connected grid).\n",
    "    The function is inspired by the A* implementation with 4-connected grid from the MICRO-452: Basics of Mobile Robotics by Professor Francesco Mondada.\n",
    "    \n",
    "    Parameters:\n",
    "    map_grid (matrix): The input map with value 0 for unoccupied cells and -1 for occupied cells (obstacles).\n",
    "    start (tuple): The input start position.\n",
    "    goal (tuple): The input goal position.\n",
    "    \n",
    "    Return:\n",
    "    list: The output path as a list of tuples which are sub-goals to be covered to travel from the start position to the goal position.    \n",
    "    \"\"\"\n",
    "    \n",
    "    def lowest_f_costs(open_list, f_costs):\n",
    "        # identify the cell in open_list wwith the lowest f_cost\n",
    "        lowest_idx = 0\n",
    "        for i in range(len(open_list)):\n",
    "            if f_costs[open_list[i]] < f_costs[open_list[lowest_idx]]:\n",
    "                lowest_idx = i\n",
    "        return lowest_idx\n",
    "        \n",
    "    # initialization\n",
    "    open_list = [start] # track unexplored cells\n",
    "    explored = [] # track explored cells\n",
    "    \n",
    "    came_from = {} # track parent cell of each cells\n",
    "    g_costs = {start: 0} # g_cost at each cells\n",
    "    f_costs = {start: heuristic(start, goal)} # f_cost at each cells = g_cost + h_cost (heuristic)\n",
    "    \n",
    "    while open_list:\n",
    "        # pop the cell with the lowest f_cost from the open set\n",
    "        current_idx = lowest_f_costs(open_list, f_costs)\n",
    "        current_pos = open_list.pop(current_idx)\n",
    "        explored.append(current_pos)\n",
    "\n",
    "        # reconstruct path\n",
    "        if current_pos == goal:\n",
    "            break\n",
    "        \n",
    "        # get the neighbors of the current cell\n",
    "        neighbors = [\n",
    "            (current_pos[0] - 1, current_pos[1]),     # up\n",
    "            (current_pos[0] + 1, current_pos[1]),     # down\n",
    "            (current_pos[0], current_pos[1] - 1),     # left\n",
    "            (current_pos[0], current_pos[1] + 1),     # right\n",
    "            \n",
    "            (current_pos[0] - 1, current_pos[1] - 1), # top-left\n",
    "            (current_pos[0] - 1, current_pos[1] + 1), # top-right\n",
    "            (current_pos[0] + 1, current_pos[1] - 1), # bottom-left\n",
    "            (current_pos[0] + 1, current_pos[1] + 1)  # bottom-right\n",
    "        ]\n",
    "\n",
    "        for neighbor in neighbors:\n",
    "            # check if neighbor is within bounds and not an obstacle\n",
    "            if (0 <= neighbor[0] < map_grid.shape[0]) and (0 <= neighbor[1] < map_grid.shape[1]):\n",
    "                if map_grid[neighbor[0], neighbor[1]] != -1 and neighbor not in explored:\n",
    "                    # calculate g_costs_updated, considering diagonal steps and probably add cost to g_scores if cells are near obstacles\n",
    "                    if (neighbor[0] != current_pos[0]) and (neighbor[1] != current_pos[1]):\n",
    "                        g_costs_updated = g_costs[current_pos] + np.sqrt(2)  # diagonal move cost\n",
    "                    else:\n",
    "                        g_costs_updated = g_costs[current_pos] + 1  # adjacent move cost\n",
    "\n",
    "                    # record the best path\n",
    "                    if neighbor not in g_costs or g_costs_updated < g_costs[neighbor]:\n",
    "                        came_from[neighbor] = current_pos\n",
    "                        g_costs[neighbor] = g_costs_updated\n",
    "                        f_costs[neighbor] = g_costs_updated + heuristic(neighbor, goal)\n",
    "\n",
    "                        if neighbor not in open_list:\n",
    "                            open_list.append(neighbor)\n",
    "\n",
    "    # reconstruct path\n",
    "    if current_pos == goal:\n",
    "        path = []\n",
    "        while current_pos in came_from:\n",
    "            path.append(current_pos)\n",
    "            current_pos = came_from[current_pos]\n",
    "        path.append(start)\n",
    "        path.reverse()\n",
    "        return path\n",
    "    else:\n",
    "        # no path was found\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thymio_transform_path(path, start):\n",
    "    \"\"\"\n",
    "    Transform the path from vision reference (y-axis right-sided, x-axis downward) to\n",
    "    new reference with origin at the start position (y-axis upward, x-axis right-sided).\n",
    "    \n",
    "    Parameters: \n",
    "    path (list): The input path as a list of tuples which are sub-goals to be covered to travel from the start position to the goal position. \n",
    "    start (tuple): The input start position.\n",
    "    \n",
    "    Return:\n",
    "    list: The ouput path as a list of tuples (sub-goals) in the new reference at the start position.\n",
    "    \"\"\"\n",
    "    \n",
    "    start_x, start_y = start\n",
    " \n",
    "    path_transformed = []\n",
    "\n",
    "    # transform the reference\n",
    "    for x, y in path:\n",
    "        new_x = (y - start_y)\n",
    "        new_y = -(x - start_x)\n",
    "        \n",
    "        path_transformed.append((new_x, new_y))\n",
    "        \n",
    "    return path_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_combining(path):\n",
    "    \"\"\"\n",
    "    Add the orientation toward the subsequent sub-goal for each sub-goal in the path, which will be used to simplify the path later.\n",
    "    \n",
    "    Parameters:\n",
    "    path (list): The input path as a list of tuples which are sub-goals to be covered to travel from the start position to the goal position.\n",
    "    \n",
    "    Return:\n",
    "    list: The ouput path as a list of tuples (sub-goals) with orientation toward the subsequent sub-goal.\n",
    "    \"\"\"\n",
    "    \n",
    "    path_translate = path\n",
    "    path_rotate = []\n",
    "    path_combined = []\n",
    "    \n",
    "    # check if the map has at least 2 points\n",
    "    if len(path) < 2:\n",
    "        return [] \n",
    "    \n",
    "    # calculate robot's orientation at each position toward the subsequent sub-goal\n",
    "    for i in range(len(path_translate) - 1):\n",
    "        dx = path_translate[i+1][0] - path_translate[i][0]\n",
    "        dy = path_translate[i+1][1] - path_translate[i][1]\n",
    "        \n",
    "        angle = np.arctan2(dy, dx)\n",
    "        \n",
    "        path_rotate.append(angle)\n",
    "    \n",
    "    # generate final path with both positions and orientation\n",
    "    for i in range(len(path_translate) - 1):\n",
    "        x_coordinate = path_translate[i][0]\n",
    "        y_coordinate = path_translate[i][1]\n",
    "        angle = path_rotate[i]\n",
    "        \n",
    "        path_combined.append((x_coordinate, y_coordinate, angle))\n",
    "    \n",
    "    if path:\n",
    "        last_point = path[-1]\n",
    "        last_angle = path_rotate[-1] if path_rotate else 0  # default to 0 if no angles calculated\n",
    "        path_combined.append((last_point[0], last_point[1], last_angle))\n",
    "    \n",
    "    return path_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_finalizing(path, start, scale_factor = SCALING_FACTOR):\n",
    "    \"\"\"\n",
    "    Simplify the path by reducing the sub-goals with the same orientation toward the subsequent sub-goals\n",
    "    and convert to the real world scale.\n",
    "    \n",
    "    Parameters:\n",
    "    path (list): The input path as a list of tuples (sub-goals) with orientation toward the subsequent sub-goal.\n",
    "    start (tuple): The input start position.\n",
    "    scale_factor (float): The input scaler to convert from matrix world (in pixels) to real world (in milimeters).\n",
    "    \n",
    "    Return:\n",
    "    list: The output simplified path as a list of tuples (critical sub-goals) and converted to real world in milimeter scale.\n",
    "    \"\"\"\n",
    "    \n",
    "    path = thymio_transform_path(path, start)\n",
    "    path = path_combining(path)\n",
    "    \n",
    "    path_final = [path[0]]\n",
    "    \n",
    "    # simplify the path into critical sub-goals by reducing ones with the same orientation\n",
    "    for pose in path[1:]:\n",
    "        if pose[2] != path_final[-1][2]:\n",
    "            path_final.append(pose)\n",
    "    \n",
    "    # add goal position to the list\n",
    "    path_final.append(path[-1])\n",
    "\n",
    "    # convert the matrix world (in pixels) to real world (in milimeters)\n",
    "    path = [(x * scale_factor, y * scale_factor, z) for x, y, z in path]     \n",
    "        \n",
    "    return path_final # (x, y, theta_rad)_t_reduced_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The state variable for the Kalman filter are \n",
    "\n",
    "\\begin{cases}\n",
    "   x_{+} = x_{0} + v*\\Delta_{t}*cos(\\theta)\\\\\n",
    "   y_{+} = y_{0} + v*\\Delta_{t}*sin(\\theta)\\\\\n",
    "   \\theta_{+} = \\theta_{0} + \\phi\\\\\n",
    "   v_{right}\\\\\n",
    "   v_{left}\n",
    "\\end{cases}\n",
    "\n",
    "This allow us to first calculate the Jacobian matrix. Furthermore, we distinguish between two cases: the first case occurs when the camera is obscured, in which only the left and right speed states are accessible. The second case applies when the camera is not hidden, and all state variables are utilized.\n",
    "\n",
    "To determine the components of the process noise and measurement noise matrices, we conducted several experiments with the Thymio. For example, we instructed it to travel a certain distance for 10 seconds before stopping. We then measured the distance it covered. By repeating this experiment multiple times, we obtained a dataset with varying positions, from which we extracted  the variance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_est= y_est =  0 \n",
    "is_initialized = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La variance de la position est : 0.00017508650519031173\n",
      "La variance de l'angle est : 0.0009884083044982715\n",
      "La variance de la vitesse basé sur la position est : 0.017806122448979594\n",
      "La variance de la position basé sur l'odom est : 0.0006906666666666697\n",
      "La variance de la vitesse est : 0.19704374999999993\n",
      "La variance de l'angle basé sur l'odoom est : 0.0034459288888888853\n",
      "La variance de la position basé sur la vision est : 2.7744000000000093\n",
      "La variance de l'angle basé sur la vision est : 9.008999999999663e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_position = [1.85,1.83,1.86,1.87,1.84,1.87,1.85,1.84,1.83,1.85,1.84,1.83,1.85,1.87,1.85,1.86,1.84] #mm for 1step de 0.1s\n",
    "data_angle = [2.24,2.21,2.20,2.18,2.185,2.17,2.19,2.165,2.14,2.12,2.185,2.15,2.16,2.15,2.12,2.13,2.16] #rad for 1 step every 0.1s\n",
    "data_sp_based_pos = [18.5,18.3,18.6,18.7,18.4,18.7,18.5,18.4,18.3,18.5,18.7,18.5,18.6,18.4] #mm/s extracted from the position measured during 10s\n",
    "data_mean_speed_measured = np.array([51.5,60,56,52.5,49.5,56,51.5,45.5,53,51.5,53.5,59.5,51.5,49,55,49.5])*THYMIO_MMS # mm/s, for the R matrix \n",
    "data_pos_odom =[2.91,2.93,2.97,2.92,2.93,2.91,2.90,2.91,2.97,2.90,2.90,2.90,2.87,2.89,2.90] #mm every 0.1s for 10s\n",
    "data_angle_odom = [6.023,6.208,6.204,6.151,6.086,6.113,6.151,6.166,6.057,6.169,6.165,6.065,6.155,6.240,6.116]\n",
    "\n",
    "#vision value\n",
    "data_vision_position_x_y = [76.6, 80, 76.6, 76.6, 76.6, 80, 80, 76.6,76.6, 80]\n",
    "data_vision_angle = [6.248, 6.265, 6.248, 6.230, 6.248, 6.230, 6.248, 6.248, 6.248, 6.248]\n",
    "\n",
    "# Calcul de la moyenne et de l'écart-type\n",
    "#1\n",
    "mean_pos = 0 #np.mean(data_position)\n",
    "std_dev_pos = np.std(data_position)\n",
    "\n",
    "#2\n",
    "mean_angle = 0.3 #np.mean(data_angle)\n",
    "std_dev_angle = np.std(data_angle)\n",
    "\n",
    "#3\n",
    "mean_spd = np.mean(data_mean_speed_measured)\n",
    "std_dev_spd = np.std(data_mean_speed_measured)\n",
    "\n",
    "#4\n",
    "mean_spd_pos = np.mean(data_sp_based_pos)\n",
    "std_dev_spd_pos = np.std(data_sp_based_pos)\n",
    "\n",
    "#5\n",
    "mean_pos_odom = np.mean(data_pos_odom)\n",
    "std_pos_odom = np.std(data_pos_odom)\n",
    "\n",
    "#6\n",
    "mean_angle_odom = 0.30 #np.mean(data_angle_odom)\n",
    "std_angle_odom = np.std(data_angle_odom)\n",
    "\n",
    "#7\n",
    "mean_vision_position_x_y = 0 #np.mean(data_vision_position_x_y)\n",
    "std_vision_position_x_y = np.std(data_vision_position_x_y)\n",
    "\n",
    "#8\n",
    "mean_vision_angle = np.mean(data_vision_angle)\n",
    "std_vision_angle = np.std(data_vision_angle)\n",
    "\n",
    "\n",
    "x1 = np.linspace(mean_pos - 3*std_dev_pos, mean_pos + 3*std_dev_pos, 500)  # Intervalle autour de la moyenne\n",
    "y1 = (1 / (std_dev_pos * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x1 - mean_pos) / std_dev_pos) ** 2)\n",
    "\n",
    "x2 = np.linspace(mean_angle - 3*std_dev_angle, mean_angle + 3*std_dev_angle, 500)  # Intervalle autour de la moyenne\n",
    "y2 = (1 / (std_dev_angle * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x2 - mean_angle) / std_dev_angle) ** 2)\n",
    "\n",
    "x3 = np.linspace(mean_spd - 3*std_dev_spd, mean_spd + 3*std_dev_spd, 500)  # Intervalle autour de la moyenne\n",
    "y3 = (1 / (std_dev_spd * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x3 - mean_spd) / std_dev_spd) ** 2)\n",
    "\n",
    "x4 = np.linspace(mean_spd_pos - 3*std_dev_spd_pos , mean_spd_pos + 3*std_dev_spd_pos , 500)  # Intervalle autour de la moyenne\n",
    "y4 = (1 / (std_dev_spd_pos  * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x4 - mean_spd_pos) / std_dev_spd_pos ) ** 2)\n",
    "\n",
    "x5 = np.linspace(mean_pos_odom - 3*std_pos_odom , mean_pos_odom + 3*std_pos_odom , 500)  # Intervalle autour de la moyenne\n",
    "y5 = (1 / (std_pos_odom  * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x5 - mean_pos_odom) / std_pos_odom ) ** 2)\n",
    "\n",
    "x6 = np.linspace(mean_angle_odom - 3*std_angle_odom , mean_angle_odom + 3*std_angle_odom , 500)  # Intervalle autour de la moyenne\n",
    "y6 = (1 / (std_angle_odom  * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x6 - mean_angle_odom) / std_angle_odom ) ** 2)\n",
    "\n",
    "x7= np.linspace(mean_vision_position_x_y - 3*std_vision_position_x_y , mean_vision_position_x_y + 3*std_vision_position_x_y , 500)  # Intervalle autour de la moyenne\n",
    "y7 = (1 / (std_vision_position_x_y  * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x7 - mean_vision_position_x_y) / std_vision_position_x_y ) ** 2)\n",
    "\n",
    "x8= np.linspace(mean_vision_angle - 3*std_vision_angle , mean_vision_angle + 3*std_vision_angle , 500)  # Intervalle autour de la moyenne\n",
    "y8 = (1 / (std_vision_angle  * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x8 - mean_vision_angle) / std_vision_angle ) ** 2)\n",
    "\n",
    "#Valeur de la variance de la position \n",
    "variance_pos = np.var(data_position)\n",
    "\n",
    "variance_angle = np.var(data_angle)\n",
    "\n",
    "variance_speed = np.var(data_mean_speed_measured)\n",
    "\n",
    "variance_speed_pos = np.var(data_sp_based_pos)\n",
    "\n",
    "variance_pos_odom = np.var(data_pos_odom)\n",
    "\n",
    "variance_angle_odom = np.var(data_angle_odom)\n",
    "\n",
    "variance_position_vision = np.var(data_vision_position_x_y) \n",
    "\n",
    "variance_angle_vision = np.var(data_vision_angle)\n",
    "\n",
    "print(f\"La variance de la position est : {variance_pos}\")#q_x and q_y\n",
    "print(f\"La variance de l'angle est : {variance_angle}\")#q_theta\n",
    "print(f\"La variance de la vitesse basé sur la position est : {variance_speed_pos}\")#q_v_x and q_v_y\n",
    "\n",
    "print(f\"La variance de la position basé sur l'odom est : {variance_pos_odom}\") #R_x and R_y\n",
    "print(f\"La variance de la vitesse est : {variance_speed}\")#R_v_x and R_v_y\n",
    "print(f\"La variance de l'angle basé sur l'odoom est : {variance_angle_odom}\")#R_theta\n",
    "\n",
    "print(f\"La variance de la position basé sur la vision est : {variance_position_vision}\")#R_x_vision\n",
    "print(f\"La variance de l'angle basé sur la vision est : {variance_angle_vision}\")#R_angle_vision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "y1_normalized = y1 / max(y1)\n",
    "y2_normalized = y2 / max(y2)\n",
    "y3_normalized = y3 / max(y3)\n",
    "y4_normalized = y4 / max(y4)\n",
    "y5_normalized = y5 / max(y5)\n",
    "y6_normalized = y6 / max(y6)\n",
    "y7_normalized = y7 / max(y7)\n",
    "y8_normalized = y8 / max(y8)\n",
    "\n",
    "# Tracé des distributions sur le même graphique\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.xlim(-0.5, 0.5)\n",
    "\n",
    "# Ajout de chaque courbe au graphique avec normalisation\n",
    "plt.plot(x1, y1_normalized, label=\"Position (data_position)\", alpha=0.8)\n",
    "plt.plot(x2, y2_normalized, label=\"Angle (data_angle)\", alpha=0.8)\n",
    "# plt.plot(x3, y3_normalized, label=\"Vitesse mesurée (data_mean_speed_measured)\", alpha=0.8)\n",
    "# plt.plot(x4, y4_normalized, label=\"Vitesse basée sur la position (data_sp_based_pos)\", alpha=0.8)\n",
    "# plt.plot(x5, y5_normalized, label=\"Position (odométrie, data_pos_odom)\", alpha=0.8)\n",
    "plt.plot(x6, y6_normalized, label=\"Angle (odométrie, data_angle_odom)\", alpha=0.8)\n",
    "plt.plot(x7, y7_normalized, label=\"Position (vision, data_vision_position_x_y)\", alpha=0.8)\n",
    "# plt.plot(x8, y8_normalized, label=\"Angle (vision, data_vision_angle)\", alpha=0.8)\n",
    "\n",
    "# Configuration des axes et de la légende\n",
    "plt.title(\"Distributions normalisées des données avec courbes gaussiennes\", fontsize=16)\n",
    "plt.xlabel(\"Valeurs normalisées\", fontsize=14)\n",
    "plt.ylabel(\"Densité de probabilité relative\", fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "\n",
    "# Affichage du graphique\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odometrie(x_prev,y_prev,theta_prev,motor_r,motor_l):\n",
    "   \n",
    "    v = (motor_r + motor_l)*THYMIO_MMS/2\n",
    "    w = (motor_r - motor_l)*THYMIO_MMS\n",
    "\n",
    "    theta = theta_prev  + w*DELTA_T/D_BASELINE\n",
    "    \n",
    "    x = x_prev + v*DELTA_T*np.cos(theta_prev)\n",
    "    y = y_prev + v*DELTA_T*np.sin(theta_prev)\n",
    "\n",
    "    return x,y, theta , motor_r, motor_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jacobien(theta, v_right, v_left): \n",
    "    \"\"\"\n",
    "    Computes the Jacobian matrix for the Kalman filter, \n",
    "    \"\"\"\n",
    "    alpha = THYMIO_MMS * (v_right + v_left) / 2\n",
    "    beta = THYMIO_MMS * (v_right - v_left) / D_BASELINE\n",
    "\n",
    "    A = - (alpha * DELTA_T * np.sin(theta + DELTA_T * beta))\n",
    "    B = (1/2) * DELTA_T * np.cos(theta + DELTA_T * beta) - (alpha * (1 / D_BASELINE) * DELTA_T**2 * np.sin(theta + DELTA_T * beta))\n",
    "    C = (1/2) * DELTA_T * np.cos(theta + DELTA_T * beta) + (alpha * (1 / D_BASELINE) * DELTA_T**2 * np.cos(theta + DELTA_T * beta))\n",
    "    D = alpha * DELTA_T * np.cos(theta + DELTA_T * beta)\n",
    "    E = (1/2) * DELTA_T * np.sin(theta + DELTA_T * beta) + (alpha * (1 / D_BASELINE) * DELTA_T**2 * np.cos(theta + DELTA_T * beta))\n",
    "    F = (1/2) * DELTA_T * np.sin(theta + DELTA_T * beta) - (alpha * (1 / D_BASELINE) * DELTA_T**2 * np.cos(theta + DELTA_T * beta))\n",
    "    G = DELTA_T/D_BASELINE\n",
    "    H = -DELTA_T/D_BASELINE\n",
    "    \n",
    "    J = np.array([[1, 0, A, B, C],\n",
    "                  [0, 1, D, E, F],\n",
    "                  [0, 0, 1, G, H],\n",
    "                  [0, 0, 0, 1, 0],\n",
    "                  [0, 0, 0, 0, 1]])\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_x = q_y = 0.00017\n",
    "# q_theta = 0.00098\n",
    "# q_vx = q_vy = 0.0178\n",
    "\n",
    "# r_x = r_y = 5.396e-05\n",
    "# r_theta = 9.008e-05\n",
    "# r_vx = r_vy = 1.213\n",
    "\n",
    "# C_not_obstructed = np.eye(5)\n",
    "\n",
    "# C_obstructed = np.array([\n",
    "#                         [0,0,0,1,0],\n",
    "#                         [0,0,0,0,1],\n",
    "#                         ])\n",
    "\n",
    "# R_obstructed = np.array([[1.21,0],\n",
    "#                         [0,1.21]])\n",
    "\n",
    "# R_not_obstructed = np.array([\n",
    "#                         [r_x,0,0,0,0],\n",
    "#                         [0,r_y,0,0,0],\n",
    "#                         [0,0,r_theta,0,0],\n",
    "#                         [0,0,0, r_vx,0],\n",
    "#                         [0,0,0,0, r_vy]\n",
    "#                         ])\n",
    "\n",
    "# Q = np.array([\n",
    "#             [q_x,0,0,0,0],\n",
    "#             [0,q_y,0,0,0],\n",
    "#             [0,0,q_theta,0,0],\n",
    "#             [0,0,0,q_vx,0],\n",
    "#             [0,0,0,0,q_vy]\n",
    "#             ])\n",
    "q_x = q_y = 2.74e-1\n",
    "q_theta = 1.24e-1\n",
    "q_vx = q_vy = 1.52\n",
    "x_odom = y_odom = 0\n",
    "\n",
    "def EKF(x, y, theta, v_r, v_l, mu_pred_prev, u_state_prev, sigma_pred_prev, R ,C, not_vision):\n",
    "    \n",
    "    # if not_vision:\n",
    "            \n",
    "        # Odometry Calculation\n",
    "        # v = (v_r + v_l)*THYMIO_MMS/2\n",
    "        # w = (v_r - v_l)*THYMIO_MMS\n",
    "        # theta -=  w*DELTA_T/D_BASELINE\n",
    "\n",
    "        # x += v*DELTA_T*np.cos(theta)\n",
    "        # y += v*DELTA_T*np.sin(theta)\n",
    "        # x_odom,y_odom,theta,_,_= odometrie(x_odom,y_odom,theta, v_r, v_l)\n",
    "\n",
    "   \n",
    "\n",
    "    A = np.array([[1, 0, 0, 0, 0],\n",
    "             [0, 1, 0, 0, 0],\n",
    "             [0, 0, 1, 0, 0],\n",
    "             [0, 0, 0, 0, 0],\n",
    "             [0, 0, 0, 0, 0]])\n",
    "    \n",
    "    Q = np.array([\n",
    "            [q_x,0,0,0,0],\n",
    "            [0,q_y,0,0,0],\n",
    "            [0,0,q_theta,0,0],\n",
    "            [0,0,0,q_vx,0],\n",
    "            [0,0,0,0,q_vy]\n",
    "            ])\n",
    "\n",
    "    B = np.array([[DELTA_T*THYMIO_MMS*np.cos(theta)/2, DELTA_T*THYMIO_MMS*np.cos(theta)/2],\n",
    "              [DELTA_T*THYMIO_MMS*np.sin(theta)/2, DELTA_T*THYMIO_MMS*np.sin(theta)/2],\n",
    "              [DELTA_T*THYMIO_MMS/D_BASELINE, -DELTA_T*THYMIO_MMS//D_BASELINE],\n",
    "              [1, 0],\n",
    "              [0, 1]])\n",
    "    \n",
    "    # Prediction Phase\n",
    "    mu_pred = np.dot(A,mu_pred_prev) + np.dot(B,u_state_prev)\n",
    "    sigma_pred = np.matmul(np.matmul(Jacobien(theta, v_r, v_l),sigma_pred_prev),np.transpose(Jacobien(theta, v_r, v_l))) + Q \n",
    "\n",
    "    ## # Innovation Phase\n",
    "    # if  not_vision:\n",
    "    #     y = np.array([[x_odom],[y_odom],[theta],[v_r],[v_l]])\n",
    "    # else:\n",
    "    y = np.array([[x],[y],[theta],[v_r],[v_l]])\n",
    "        \n",
    "    inno = y -np.dot(C, mu_pred)\n",
    "\n",
    "    S = np.matmul(np.matmul(C,sigma_pred),np.transpose(C)) + R \n",
    "\n",
    "    K_gain = np.matmul(np.matmul(sigma_pred,np.transpose(C)),np.linalg.inv(S))\n",
    "\n",
    "    # Posteriori\n",
    "\n",
    "    mu_post = mu_pred + np.dot(K_gain,inno)\n",
    "    sigma_post = np.matmul(np.subtract(np.eye(5),np.matmul(K_gain,C)),sigma_pred)\n",
    "\n",
    "    return mu_post, sigma_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Kalman_system(is_cam_obstructed, x_odom, y_odom, theta_odom, x_vision, y_vision, theta_vision, v_r, v_l):\n",
    "\n",
    "#     #global is_cam_obstructed, x_odom, y_odom, theta_odom, x_vision, y_vision, theta_vision, v_r, v_l\n",
    "\n",
    "#     mu_pred_prev = np.transpose(np.array([x_vision, y_vision, theta_vision, 0, 0]))\n",
    "#     u_state_prev = np.transpose(np.array([0,0]))\n",
    "#     sigma_pred_prev = 0\n",
    "\n",
    "# if not is_cam_obstructed:\n",
    "    \n",
    "#     mu_post_vision, sigma_post_vision = EKF(x_vision, y_vision, theta_vision, 0, 0, mu_pred_prev, u_state_prev)\n",
    "\n",
    "# else:\n",
    "#     mu_post_odom, sigma_post_odom, sigma_pred_prev, mu_pred_prev, u_state_prev = EKF(0, 0, 0, v_r, v_l, mu_pred_prev, u_state_prev)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigma_est = np.eyes(5)\n",
    "\n",
    "# def kalman_filter(x_vision,y_vision,theta_vision,spd_right,spd_left,Sigma, is_cam_obstructed, theta_shift_vision_init):\n",
    "\n",
    "#         \"\"\"\n",
    "#         Kalman Filter\n",
    "#         :param Q: Process noise matrix\n",
    "#         :param R: Measurement noise matrix\n",
    "#         \"\"\"\n",
    "        \n",
    "#         global Q,C_obstructed,C_not_obstructed,R_obstructed,R_not_obstructed, x_est, y_est, theta_est, is_initialized\n",
    "#         # print('valeur theta shift: ', theta_shift_vision_init)\n",
    "        \n",
    "#         if not is_initialized:\n",
    "#                 theta_est = theta_shift_vision_init\n",
    "#                 # print('inside')\n",
    "#                 is_initialized = True  \n",
    "\n",
    "#         q_x = q_y = 0.00017\n",
    "#         q_theta = 0.00098\n",
    "#         q_vx = q_vy = 0.0178\n",
    "\n",
    "#         r_x = r_y = 5.396e-05\n",
    "#         r_theta = 9.008e-05\n",
    "#         r_vx = r_vy = 1.213\n",
    "\n",
    "#         # #vision coeff\n",
    "#         # r_x_vision = r_y_vision = 5.396e-05\n",
    "#         # r_theta_vision = 9.008e-05\n",
    "#         # r_vx = r_vy = 1.213\n",
    "\n",
    "#         Q = np.array([\n",
    "#                 [q_x,0,0,0,0],\n",
    "#                 [0,q_y,0,0,0],\n",
    "#                 [0,0,q_theta,0,0],\n",
    "#                 [0,0,0,q_vx,0],\n",
    "#                 [0,0,0,0,q_vy]\n",
    "#                 ])\n",
    "\n",
    "#         C_obstructed = np.array([\n",
    "#                          [0,0,0,1,0],\n",
    "#                          [0,0,0,0,1],\n",
    "#                          ])\n",
    "    \n",
    "#         C_not_obstructed = np.eye(5)\n",
    "    \n",
    "#         R_obstructed = np.array([[1.21,0],\n",
    "#                             [0,1.21]])\n",
    "    \n",
    "#         R_not_obstructed = np.array([\n",
    "#                                 [r_x,0,0,0,0],\n",
    "#                                 [0,r_y,0,0,0],\n",
    "#                                 [0,0,r_theta,0,0],\n",
    "#                                 [0,0,0, r_vx,0],\n",
    "#                                 [0,0,0,0, r_vy]\n",
    "#                                 ])\n",
    "\n",
    "\n",
    "#         # 1/ Estimation of mean of states\n",
    "        \n",
    "#         # # print('x_odom, y_odom and theta_odom from inside the kalmann: ', x_est, y_est, np.rad2deg(theta_est))\n",
    "#         # x_est, y_est, theta_est, spd_right_est, spd_left_est = odometrie(x_est,y_est,theta_est,spd_right,spd_left)\n",
    "#         # # theta_est = normalize_angle(theta_est)\n",
    "#         # print('x_odom, y_odom and theta_odom from inside the kalmann: ', x_est, y_est, np.rad2deg(theta_est))\n",
    "        \n",
    "#         # mu_est = np.array([[x_est],[y_est],[theta_est],[spd_right_est],[spd_left_est]])\n",
    "        \n",
    "#         # 2/ Estimation of variance of states\n",
    "           \n",
    "        \n",
    "#         # test if vision is obstructed or not:\n",
    "#         if is_cam_obstructed:\n",
    "\n",
    "#                  # print('x_odom, y_odom and theta_odom from inside the kalmann: ', x_est, y_est, np.rad2deg(theta_est))\n",
    "#                 x_est, y_est, theta_est, spd_right_est, spd_left_est = odometrie(x_est,y_est,theta_est,spd_right,spd_left)\n",
    "#                 # theta_est = normalize_angle(theta_est)\n",
    "#                 print('x_odom, y_odom and theta_odom from inside the kalmann: ', x_est, y_est, np.rad2deg(theta_est))\n",
    "                \n",
    "#                 mu_est = np.array([[x_est],[y_est],[theta_est],[spd_right_est],[spd_left_est]])\n",
    "#                 jacobien = Jacobien(theta_est,spd_right_est,spd_left_est)\n",
    "#                 Sigma_est = np.matmul(np.matmul(jacobien,Sigma),np.transpose(jacobien))+Q\n",
    "         \n",
    "#                 # 3/ Gain de correction optimal\n",
    "#                 S = np.matmul(np.matmul(C_obstructed,Sigma_est),np.transpose(C_obstructed))+R_obstructed\n",
    "#                 K = np.matmul(np.matmul(Sigma_est,np.transpose(C_obstructed)),np.linalg.inv(S))\n",
    "        \n",
    "#                 # 4/ Update with the measure \n",
    "#                 y = np.array([[spd_right_est],[spd_left_est]])\n",
    "#                 y_reel = np.array([[spd_right],[spd_left]]) \n",
    "#                 mu_updated = mu_est + np.matmul(K,y)\n",
    "        \n",
    "#                 # 5/ Update the variance\n",
    "#                 Sigma_updated = np.matmul(np.subtract(np.eye(5),np.matmul(K,C_obstructed)),Sigma_est)\n",
    "\n",
    "#                 return mu_updated[0][0],mu_updated[1][0],mu_updated[2][0],mu_updated[3][0],mu_updated[4][0],Sigma_updated # mu_est for x,y and theta and mu_reel for speeds\n",
    "        \n",
    "#         else: # cam is not obstructed\n",
    "                \n",
    "#                 # 3/ Gain de correction optimal\n",
    "                \n",
    "#                 S = np.matmul(np.matmul(C_not_obstructed,Sigma_est),np.transpose(C_not_obstructed))+R_not_obstructed\n",
    "#                 K = np.matmul(np.matmul(Sigma_est,np.transpose(C_not_obstructed)),np.linalg.inv(S))\n",
    "        \n",
    "#                 # 4/ Update avec la mesure (moyenne)\n",
    "#                 # y = np.array([[x_est],[y_est],[theta_est],[spd_right_est],[spd_left_est]])\n",
    "#                 # y = np.array([x_est, y_est, theta_est, spd_right_est, spd_left_est]).reshape((-1, 1))\n",
    "#                 y_reel = np.array([[x_vision],[y_vision],[theta_vision],[spd_right],[spd_left]]) #=> Changez pour vos fonctions !!!\n",
    "#                 # y_reel = np.array([x, y, theta, spd_right, spd_left]).reshape((-1, 1))\n",
    "#                 mu_updated = mu_est + np.matmul(K,y_reel) #mu innova\n",
    "#                 # mu_updated = mu_est + np.matmul(K, y_reel - y)\n",
    "\n",
    "#                 # 5/ Update de la variance avec la mesure\n",
    "#                 Sigma_updated = np.matmul(np.subtract(np.eye(5),np.matmul(K,C_not_obstructed)),Sigma_est)\n",
    "#                 # mu_updated[2][0] = normalize_angle(mu_updated[2][0]) #normalisation angle\n",
    "                \n",
    "#                 return mu_updated[0][0],mu_updated[1][0],mu_updated[2][0],mu_updated[3][0],mu_updated[4][0],Sigma_updated # mu_reel for all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motion Control Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motor_speed = 100\n",
    "count_control = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This control strategy will perform correction based on the angle difference between the desired orientation from current position toward the subsequent sub-goal and the current robot's position (angle_error = angle_target - angle_robot, hence |angle_error| < 2π since |angle_target|, |angler_robot| < π thanks to np.arctan2 and normalize_angle functions, respectively) where the higher the difference, the stronger the correction. There are 2 cases:\n",
    "* angle_error < π: if the difference is larger than 0, meaning the desired orientation is larger than the current one, the robot will rotate counter-clockwise by having the left motor's speed smaller than the right; and vice versa, if the difference is smaller than 0, meaning the desired orientation is smaller than the current one, the robot will rotate clockwise by having the left motor's speed larger than the right.\n",
    "* angle_error > π: the condition with π is to avoid the robot from rotating unnecessary larger angle (π + |Ѳ| > π) but more effective angle (2π - angle_error < π) to avoid dramatic movement and reduce the orientation variance of the odometry; the control strategy will be reversed from the first case where if the difference is larger than 0, the robot will rotate clockwise by having the left motor's speed larger than the right; and vice versa, if the difference is smaller than 0, the robot will rotate counter-clockwise by having the left motor's speed smaller than the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_control(angle_error, kp, motor_speed):\n",
    "   \"\"\"\n",
    "   Control the robot motors' speed to follow the predefined path by utilizing P controller\n",
    "   to compromise the angle error between desired orientation from current position toward subsequent sub-goal and current orientation.\n",
    "\n",
    "   Parameters:\n",
    "   angle_error (float): The input angle difference between desired orientation from current position toward sub-goal and current orientation.\n",
    "   kp (float): The input gain for P controller.\n",
    "   motor_speed (float): The input speed for both right and left wheel motors.\n",
    "   \n",
    "   Return:\n",
    "   float: The output right motor's speed.\n",
    "   float: The output left motor's speed.\n",
    "   \"\"\"\n",
    "   \n",
    "   # difference between the desired and current orientation is smaller than π\n",
    "   if abs(angle_error) < np.pi:\n",
    "      p_correction = kp * abs(angle_error) \n",
    "      if angle_error < 0.0:\n",
    "         motor_left = int(motor_speed + p_correction)\n",
    "         motor_right = int(motor_speed - p_correction)\n",
    "      else:\n",
    "         motor_left = int(motor_speed - p_correction)\n",
    "         motor_right = int(motor_speed + p_correction)\n",
    "      \n",
    "   # difference between the desired and current orientation is larger than π, replace by (2π - difference) and flip the control strategy\n",
    "   else:\n",
    "      p_correction = kp * abs(2 * np.pi - angle_error)\n",
    "      if angle_error > 0.0:\n",
    "         motor_left = int(motor_speed + p_correction)\n",
    "         motor_right = int(motor_speed - p_correction)\n",
    "      else:\n",
    "         motor_left = int(motor_speed - p_correction)\n",
    "         motor_right = int(motor_speed + p_correction)\n",
    "      \n",
    "   return motor_left, motor_right "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a variable to track the current sub-goal\n",
    "count_control = 0\n",
    "\n",
    "async def motion_control(pose, path):\n",
    "    \"\"\"\n",
    "    Control the motion of the robot by continuously correcting the angle difference\n",
    "    between current orientation and desired angle toward the subgoal using P controller.\n",
    "    \n",
    "    Parameters:\n",
    "    pose (tuple): The input current position.\n",
    "    path (list): The input simplified path as a list of tuples (critical sub-goals) and converted to real world in milimeter scale.\n",
    "    \n",
    "    Return:\n",
    "    Directly change the speed of left and right motors.\n",
    "    \"\"\"\n",
    "    \n",
    "    global count_control, left_speed, right_speed\n",
    "\n",
    "    # iterate the function until all sub-goals have been reached in order\n",
    "    if count_control < len(path):\n",
    "        sub_goal = path[count_control]\n",
    "        \n",
    "        dist_x = sub_goal[0] - pose[0] # distance in x-direction from current position to sub-goal \n",
    "        dist_y = sub_goal[1] - pose[1] # distance in y-direction from current position to sub-goal \n",
    "        angle_target = np.arctan2(dist_y, dist_x) # desired angle from current position toward sub-goal\n",
    "        \n",
    "        angle_robot = normalize_angle(pose[2]) # current angle\n",
    "        angle_error = normalize_angle(angle_target - angle_robot) # angle difference between desired angle from current position toward sub-goal and current angle\n",
    "        \n",
    "        dist_to_goal = np.sqrt((dist_x)**2 + dist_y**2) # distance from current pose to sub-goal\n",
    "\n",
    "        # first correction for the starting point \n",
    "        if sub_goal[0] == sub_goal[1] == 0 and abs(sub_goal[2] - angle_robot) > np.deg2rad(10):\n",
    "            left_speed, right_speed = p_control(sub_goal[2] - angle_robot, 25, motor_speed = 0)\n",
    "            await node.set_variables(motors(left_speed, right_speed))\n",
    "\n",
    "        elif dist_to_goal >= SUCCESS_THRESHOLD:\n",
    "            \n",
    "            # slow down when reaching the goal to have more accurate movement\n",
    "            if dist_to_goal <= 40:\n",
    "                left_speed, right_speed = p_control(angle_error, 15, 40)\n",
    "                await node.set_variables(motors(left_speed, right_speed))\n",
    "            \n",
    "            # move with larger speed to reduce traveling time\n",
    "            else:\n",
    "                left_speed, right_speed = p_control(angle_error, 25, 75)\n",
    "                await node.set_variables(motors(left_speed, right_speed))\n",
    "            \n",
    "        else:\n",
    "            print('correction finished')\n",
    "            count_control += 1\n",
    "        print(sub_goal)\n",
    "        print('count: ', count_control)\n",
    "\n",
    "    else: \n",
    "        await node.set_variables(motors(0,0))\n",
    "\n",
    "    return left_speed, right_speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering Part\n",
    "x_odom_array = []\n",
    "y_odom_array = []\n",
    "\n",
    "\n",
    "sigma = np.zeros(5)\n",
    "x_kalman = []\n",
    "y_kalman = []\n",
    "\n",
    "#Initialisation des graphiques\n",
    "fig, ax, line = initialize_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corners found True\n",
      "............................................\n",
      "corners found True\n",
      "............................................\n",
      "corners found True\n",
      "............................................\n",
      "corners found True\n",
      "............................................\n",
      "corners found True\n",
      "............................................\n",
      "corners found True\n",
      "............................................\n",
      "corners found True\n",
      "............................................\n",
      "corners found True\n",
      "............................................\n",
      "corners found True\n",
      "............................................\n",
      "corners found True\n",
      "............................................\n",
      "corners found True\n",
      "............................................\n",
      "corners found True\n",
      "............................................\n",
      "corners found True\n",
      "............................................\n",
      "corners found True\n",
      "............................................\n",
      "corners found True\n",
      "............................................\n",
      "corners found True\n",
      "............................................\n",
      "corners found True\n",
      "............................................\n",
      "corners found True\n",
      "............................................\n",
      "corners found True\n",
      "............................................\n",
      "corners found True\n",
      "............................................\n",
      "corners found True\n",
      "............................................\n",
      "corners found True\n",
      "............................................\n",
      "corners found True\n",
      "............................................\n",
      "corners found True\n",
      "............................................\n",
      "corners found True\n",
      "............................................\n",
      "corners found True\n",
      "............................................\n",
      "corners found True\n",
      "............................................\n",
      "corners found True\n",
      "............................................\n",
      "corners found True\n",
      "............................................\n",
      "corners found True\n",
      "............................................\n",
      "path:  [(0.0, 0.0, -135.0), (-18.0, -18.0, 180.0), (-223.0, -18.0, 180.0)]\n",
      "theta vision init:  2.5127963671743605\n",
      "previous [572. 308.]\n",
      "current [536. 344.]\n",
      "previous [572. 308.]\n",
      "current [536. 344.]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'line'\n> Overload resolution failed:\n>  - Can't parse 'pt1'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'pt1'. Sequence item with index 0 has a wrong type\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 196\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time_diff \u001b[38;5;241m<\u001b[39m DELTA_T:\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m client\u001b[38;5;241m.\u001b[39msleep(DELTA_T \u001b[38;5;241m-\u001b[39m time_diff)\n\u001b[1;32m--> 196\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m main()\n",
      "Cell \u001b[1;32mIn[57], line 132\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    129\u001b[0m acceleration \u001b[38;5;241m=\u001b[39m node[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    131\u001b[0m bird_image \u001b[38;5;241m=\u001b[39m project_image(image, old_corners)\n\u001b[1;32m--> 132\u001b[0m bird_image \u001b[38;5;241m=\u001b[39m \u001b[43mshow_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbird_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_start\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbird image\u001b[39m\u001b[38;5;124m\"\u001b[39m, bird_image)\n\u001b[0;32m    134\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath_image.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, bird_image)\n",
      "Cell \u001b[1;32mIn[17], line 11\u001b[0m, in \u001b[0;36mshow_path\u001b[1;34m(image, path, start)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprevious\u001b[39m\u001b[38;5;124m\"\u001b[39m, previous)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent\u001b[39m\u001b[38;5;124m\"\u001b[39m, current)\n\u001b[1;32m---> 11\u001b[0m     \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevious\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     previous \u001b[38;5;241m=\u001b[39m current\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'line'\n> Overload resolution failed:\n>  - Can't parse 'pt1'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'pt1'. Sequence item with index 0 has a wrong type\n"
     ]
    }
   ],
   "source": [
    "# q_x = q_y = 2.74e-1\n",
    "# q_theta = 1.24e-1\n",
    "# q_vx = q_vy = 1.52\n",
    "\n",
    "# r_x =  0.11e-1\n",
    "# r_y = 0.21e-1\n",
    "# r_theta = 3.59e-5\n",
    "# r_vx = r_vy = 2.52\n",
    "q_x = q_y = 0.00017\n",
    "q_theta = 0.00098\n",
    "q_vx = q_vy = 0.0178\n",
    "\n",
    "r_x = r_y = 5.396e-05\n",
    "r_theta = 9.008e-05\n",
    "r_vx = r_vy = 1.213\n",
    "\n",
    "#vision coeff\n",
    "r_x_vision = r_y_vision = 5.396e-05\n",
    "r_theta_vision = 9.008e-05\n",
    "r_vx = r_vy = 1.213\n",
    "\n",
    "C_not_obstructed = np.eye(5)\n",
    "\n",
    "C_obstructed = np.array([[0,0,0,0,0],\n",
    "                         [0,0,0,0,0],\n",
    "                         [0,0,0,0,0],\n",
    "                         [0,0,0,1,0],\n",
    "                         [0,0,0,0,1],\n",
    "                         ])\n",
    "\n",
    "R_obstructed = np.array([[np.inf,0,0,0,0],\n",
    "                         [0,np.inf,0,0,0],\n",
    "                         [0,0,np.inf,0,0],\n",
    "                         [0,0,0,1.21,0],\n",
    "                        [0,0,0,0,1.21]])\n",
    "\n",
    "\n",
    "R_not_obstructed = np.array([\n",
    "                        [r_x,0,0,0,0],\n",
    "                        [0,r_y,0,0,0],\n",
    "                        [0,0,r_theta,0,0],\n",
    "                        [0,0,0, r_vx,0],\n",
    "                        [0,0,0,0, r_vy]\n",
    "                        ])\n",
    "\n",
    "Q = np.array([\n",
    "            [q_x,0,0,0,0],\n",
    "            [0,q_y,0,0,0],\n",
    "            [0,0,q_theta,0,0],\n",
    "            [0,0,0,q_vx,0],\n",
    "            [0,0,0,0,q_vy]\n",
    "            ])\n",
    "\n",
    "async def main():\n",
    "    global count_control, x_filtered, y_filtered, theta_filtered, x_odom, y_odom, theta_odom, is_cam_obstructed, thymio_position_vision,is_thymio_found,thymio_angle_vision, path, search_goal, search_start, map, mu_pred_prev, u_state_prev, sigma_pred_prev, sigma_post_odom, button_forward\n",
    "\n",
    "\n",
    "    # VISION\n",
    "    # open the default camera\n",
    "    cam = cv2.VideoCapture(1)\n",
    "    if not cam.isOpened():\n",
    "            print(\"Error: Could not open camera.\")\n",
    "\n",
    "    # convert camera resolution from 1920x1080 to 1024x768\n",
    "    cam.set(cv2.CAP_PROP_FRAME_WIDTH, 1024)\n",
    "    cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 768)\n",
    "\n",
    "    map, search_goal, search_start, theta_vision_init, old_corners = initialise_setup(cam) # in (x, y, theta_rad)_v\n",
    "\n",
    "    # INIT POUR KALMAN\n",
    "    x_vision, y_vision = thymio_transform_pose(search_start, search_start) # in (x, y, theta_rad)_t\n",
    "    \n",
    "    mu_post_vision = np.array([[x_vision], [y_vision], [theta_vision_init], [0], [0]])\n",
    "    mu_post_odom = np.array([[0], [0], [theta_vision_init], [0], [0]])\n",
    "    \n",
    "    u_state_prev = np.transpose(np.array([0,0]))\n",
    "    sigma_post_odom = np.array([\n",
    "                                [0,0,0,0,0],\n",
    "                                [0,0,0,0,0],\n",
    "                                [0,0,0,0,0],\n",
    "                                [0,0,0,0,0],\n",
    "                                [0,0,0,0,0]\n",
    "                                ])\n",
    "    \n",
    "    sigma_post_vision = np.array([\n",
    "                                [0,0,0,0,0],\n",
    "                                [0,0,0,0,0],\n",
    "                                [0,0,0,0,0],\n",
    "                                [0,0,0,0,0],\n",
    "                                [0,0,0,0,0]\n",
    "                                ])\n",
    "\n",
    "    map_image = np.float32(map.copy())\n",
    "    map_image[map == -1] = 255\n",
    "    cv2.imwrite(\"blue filter.jpg\", map_image)\n",
    "\n",
    "    # PATH PLANNING\n",
    "    # print(search_goal, search_start)\n",
    "    # print('hahah')\n",
    "    # print(map)\n",
    "    path = path_planning_a_star(map, search_start, search_goal)\n",
    "    path = path_finalizing(path, search_start, SCALING_FACTOR) # in (x, y, theta_rad)_t\n",
    "    path = [(float(x), float(y), float(theta)) for x, y, theta in path]\n",
    "    path_print = [(float(x), float(y), float(np.rad2deg(theta))) for x, y, theta in path]\n",
    "    print('path: ', path_print)\n",
    "\n",
    "    x_odom = y_odom = 0\n",
    "    theta_odom = theta_vision_init\n",
    "    print('theta vision init: ', theta_odom)\n",
    "\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "        ret, image = cam.read()\n",
    "        await node.wait_for_variables({\n",
    "            \"motor.left.speed\",\n",
    "            \"motor.right.speed\",\n",
    "            \"button.center\",\n",
    "            \"button.forward\",\n",
    "            \"prox.horizontal\",\n",
    "            \"acc\"\n",
    "        })\n",
    "\n",
    "        # variables\n",
    "        motor_left = node[\"motor.left.speed\"]\n",
    "        motor_right = node[\"motor.right.speed\"]\n",
    "        button_center = node[\"button.center\"]\n",
    "        button_forward = node[\"button.forward\"]\n",
    "        prox_horizontal = node[\"prox.horizontal\"] #tableau contenant les 7 capteurs de proximité\n",
    "        acceleration = node[\"acc\"]\n",
    "\n",
    "        bird_image = project_image(image, old_corners)\n",
    "        bird_image = show_path(bird_image, path, search_start)\n",
    "        cv2.imshow(\"bird image\", bird_image)\n",
    "        cv2.imwrite(\"path_image.png\", bird_image)\n",
    "        # FILTERING KALMAN\n",
    "        is_cam_obstructed, is_thymio_found, thymio_position_vision, theta_vision = get_thymio_pose(image, old_corners)\n",
    "        theta_vision = normalize_angle(theta_vision)\n",
    "        x_vision, y_vision = thymio_transform_pose(thymio_position_vision, search_start) # in (x, y, theta_rad)_t\n",
    "\n",
    "        if not is_cam_obstructed:\n",
    "            # print('using vision')\n",
    "            mu_post_vision, sigma_post_vision = EKF(x_vision, y_vision, theta_vision, 0, 0, mu_post_vision, u_state_prev, sigma_post_vision, R_not_obstructed, C_not_obstructed, False)\n",
    "            pose = (mu_post_vision[0, 0], mu_post_vision[1, 0], normalize_angle(mu_post_vision[2, 0]))\n",
    "\n",
    "        else:\n",
    "            # print('using odom')\n",
    "            x_odom, y_odom, theta_odom, _, _= odometrie(x_odom,y_odom,theta_odom, motor_right, motor_left)\n",
    "            theta_odom = normalize_angle(theta_odom)\n",
    "            mu_post_odom, sigma_post_odom = EKF(x_odom, y_odom, theta_odom, motor_right, motor_left, mu_post_odom, u_state_prev, sigma_post_odom, R_obstructed, C_obstructed, True)\n",
    "            pose = (float(mu_post_odom[0, 0]), float(mu_post_odom[1, 0]), normalize_angle(float(mu_post_odom[2, 0])))\n",
    "            # pose = (x_odom, y_odom, theta_odom)\n",
    "\n",
    "        # x_odom, y_odom, theta_odom, _, _= odometrie(x_odom,y_odom,theta_odom, motor_right, motor_left)\n",
    "\n",
    "        print('pose_x_vi: ', x_vision, 'pose_y_vi: ', y_vision, 'angle vision: ', np.rad2deg(theta_vision))\n",
    "        print('pose_x_odom: ', x_odom, 'pose_y_odom: ', y_odom, 'angle odom: ', np.rad2deg(theta_odom))\n",
    "        print('x filtered: ', pose[0], 'y filtered: ', pose[1], 'angle filtered: ', np.rad2deg(pose[2]))\n",
    "        # print('cam obstructed? ', is_cam_obstructed)\n",
    "\n",
    "        # MOTION CONTROL\n",
    "        u_state_prev[0],u_state_prev[1] = await motion_control(pose, path)\n",
    "        # print('u_state_prev: ', u_state_prev)\n",
    "\n",
    "        # PLOTTING\n",
    "        # x_kalman.append(x_filtered)\n",
    "        # y_kalman.append(y_filtered)\n",
    "        # line.set_data(x_kalman,y_kalman)\n",
    "\n",
    "        ## erase previous ellipses\n",
    "        # for patch in reversed(ax.patches):\n",
    "        #     patch.remove()\n",
    "\n",
    "        # add ellipses\n",
    "        # plot_gaussian(ax, [x_odom, y_odom], Sigma[:2, :2], color='red') #on prend uniquement la partie de la matrice de variance correspondante à x et y donc une sub matrice 2x2\n",
    "        # fig.canvas.draw()\n",
    "\n",
    "        # fig.canvas.flush_events()\n",
    "\n",
    "        # THYMIO DIRECT CONTROL\n",
    "        if button_forward == 1:\n",
    "            await node.set_variables(motors(100, 100))\n",
    "\n",
    "        if button_center == 1:\n",
    "            await node.set_variables(motors(0, 0))\n",
    "            x_odom = y_odom = theta_odom = 0\n",
    "            break\n",
    "\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    time_diff = time.time() - start_time\n",
    "\n",
    "    if time_diff < DELTA_T:\n",
    "        await client.sleep(DELTA_T - time_diff)\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = path_planning_a_star(map, search_start, search_goal) \n",
    "path_show = thymio_transform_path(path, search_start)\n",
    "\n",
    "# path = path_finalizing(path, search_start, SCALING_FACTOR) # in (x, y, theta_rad)_t\n",
    "# path = [(float(x), float(y), float(theta)) for x, y, theta in path]\n",
    "display_map(map, path, search_start, search_goal)\n",
    "print(path_show)\n",
    "print(search_start, search_goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = path_planning_a_star(map, search_start, search_goal) \n",
    "path_show = thymio_transform_path(path, search_start)\n",
    "\n",
    "# path = path_finalizing(path, search_start, SCALING_FACTOR) # in (x, y, theta_rad)_t\n",
    "# path = [(float(x), float(y), float(theta)) for x, y, theta in path]\n",
    "display_map(map, path, search_start, search_goal)\n",
    "print(path_show)\n",
    "print(search_start, search_goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
